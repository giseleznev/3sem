{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npIrOYmGWU7b"
      },
      "source": [
        "# Model Quantization\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/yandexdataschool/nlp_course/blob/2025/week08_efficiency/hw_8.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "In this session, you're going to implement post-training quantization approaches for _Large Language Models_, ranging from naive ones to State of The Art techniques. The main goal is to implement [GPTQ](https://arxiv.org/abs/2210.17323), with some of it's newer extension left as bonus exercises.\n",
        "\n",
        "<font color='red'>Important note:</font>\n",
        "This homework is designed to run on colab with T4 gpu. It requires at least 15Gb of *VRAM*, 12Gb of *RAM*. If your machine meets those criteria, you should be good to go too.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld5GgOmT2WE1"
      },
      "source": [
        "# Installing the Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers==4.57.1 sentencepiece==0.2.1 datasets==4.0.0 accelerate==1.11.0 Ninja==1.13.0 triton==3.4.0"
      ],
      "metadata": {
        "id": "T4g6yVlMNOO-",
        "outputId": "d16e8fd4-c06a-4bba-ba98-8521ff6e89bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.57.1 in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: sentencepiece==0.2.1 in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: datasets==4.0.0 in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate==1.11.0 in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Collecting Ninja==1.13.0\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting triton==3.4.0\n",
            "  Downloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==1.11.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==1.11.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton==3.4.0) (75.2.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1) (2025.11.12)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate==1.11.0) (1.11.1.6)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch>=2.0.0 (from accelerate==1.11.0)\n",
            "  Downloading torch-2.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.0.0->accelerate==1.11.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.0.0->accelerate==1.11.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.0.0->accelerate==1.11.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.0.0->accelerate==1.11.0)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.0.0->accelerate==1.11.0)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.0.0->accelerate==1.11.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.0.0->accelerate==1.11.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.0.0->accelerate==1.11.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.0.0->accelerate==1.11.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.0.0->accelerate==1.11.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.0.0->accelerate==1.11.0)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting torch>=2.0.0 (from accelerate==1.11.0)\n",
            "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=2.0.0->accelerate==1.11.0)\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.0.0) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==4.0.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.11.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate==1.11.0) (3.0.3)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m809.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m134.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Ninja, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.8.0 which is incompatible.\n",
            "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Ninja-1.13.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 torch-2.8.0 triton-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "id": "SO41o8AJ68Ia",
        "outputId": "d1f45f05-87ac-433d-b380-728e97527ed9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.10.2.21->torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m856.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.3.90->torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy==1.13.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m124.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0\n",
            "    Uninstalling torch-2.8.0:\n",
            "      Successfully uninstalled torch-2.8.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.0+cu126\n",
            "    Uninstalling torchvision-0.24.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.24.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.9.0+cu126\n",
            "    Uninstalling torchaudio-2.9.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtpmhiksi62J"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBpuR3vpi62J",
        "outputId": "6e8e6cb0-486b-4c4d-cfd0-4b599ef1d290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
            "env: CUDA_VISIBLE_DEVICES=0 # Change it if you're on a multy-GPU machine\n"
          ]
        }
      ],
      "source": [
        "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
        "%env CUDA_VISIBLE_DEVICES=0 # Change it if you're on a multy-GPU machine\n",
        "\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from typing import Mapping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import transformers\n",
        "from transformers.models.llama.modeling_llama import LlamaDecoderLayer, LlamaForCausalLM\n",
        "from transformers.models.llama.configuration_llama import LlamaConfig\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncYOzQJeuQSY"
      },
      "source": [
        "**INT8 and INT4 GEMM custom CUDA kernels**\n",
        "\n",
        "Along with this jupyter notebook, two `CUDA` files are provided, implementing efficient matrix multiplication for `int4` and `int8`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/cutlass.git\n",
        "!export CUDACXX=/usr/local/cuda/bin/nvcc\n",
        "!cd cutlass && mkdir build && cd build && cmake .. -DCUTLASS_NVCC_ARCHS=75\n",
        "\n",
        "!wget -nc https://raw.githubusercontent.com/yandexdataschool/nlp_course/2023/week10_efficiency/kernel.cpp --no-check-certificate\n",
        "!wget -nc https://raw.githubusercontent.com/yandexdataschool/nlp_course/2023/week10_efficiency/kernel.cu --no-check-certificate"
      ],
      "metadata": {
        "id": "OmbaXHEDuTqu",
        "outputId": "6ab7f8a1-15d7-460c-a0a0-e4e64980331a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cutlass'...\n",
            "remote: Enumerating objects: 36573, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 36573 (delta 41), reused 27 (delta 27), pack-reused 36503 (from 2)\u001b[K\n",
            "Receiving objects: 100% (36573/36573), 54.85 MiB | 16.18 MiB/s, done.\n",
            "Resolving deltas: 100% (27582/27582), done.\n",
            "Updating files: 100% (6708/6708), done.\n",
            "-- CMake Version: 3.31.6\n",
            "-- CUTLASS 4.3.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- The CUDA compiler identification is NVIDIA 12.5.82 with host compiler GNU 11.4.0\n",
            "-- Detecting CUDA compiler ABI info\n",
            "-- Detecting CUDA compiler ABI info - done\n",
            "-- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc - skipped\n",
            "-- Detecting CUDA compile features\n",
            "-- Detecting CUDA compile features - done\n",
            "-- Found CUDAToolkit: /usr/local/cuda/targets/x86_64-linux/include (found version \"12.5.82\")\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- CUDART: /usr/local/cuda/lib64/libcudart.so\n",
            "-- CUDA Driver: /usr/local/cuda/lib64/stubs/libcuda.so\n",
            "-- NVRTC: /usr/local/cuda/lib64/libnvrtc.so\n",
            "-- Default Install Location: install\n",
            "-- Found Python3: /usr/local/bin/python (found suitable version \"3.12.12\", minimum required is \"3.5\") found components: Interpreter\n",
            "-- CUDA Compilation Architectures: 75\n",
            "-- Enable caching of reference results in conv unit tests\n",
            "-- Enable rigorous conv problem sizes in conv unit tests\n",
            "-- Grid Dependency Control (GDC) is enabled for SM100 kernels (required for programmatic dependent launches).\n",
            "-- Using the following NVCC flags: \n",
            "  --expt-relaxed-constexpr\n",
            "  -ftemplate-backtrace-limit=0\n",
            "  -DCUTLASS_TEST_LEVEL=0\n",
            "  -DCUTLASS_TEST_ENABLE_CACHED_RESULTS=1\n",
            "  -DCUTLASS_CONV_UNIT_TEST_RIGOROUS_SIZE_ENABLED=1\n",
            "  -DCUTLASS_DEBUG_TRACE_LEVEL=0\n",
            "  -Xcompiler=-Wconversion\n",
            "  -Xcompiler=-fno-strict-aliasing\n",
            "\u001b[33mCMake Warning (dev) at /usr/local/lib/python3.12/dist-packages/cmake/data/share/cmake-3.31/Modules/FetchContent.cmake:1953 (message):\n",
            "  Calling FetchContent_Populate(googletest) is deprecated, call\n",
            "  FetchContent_MakeAvailable(googletest) instead.  Policy CMP0169 can be set\n",
            "  to OLD to allow FetchContent_Populate(googletest) to be called directly for\n",
            "  now, but the ability to call it with declared details will be removed\n",
            "  completely in a future version.\n",
            "Call Stack (most recent call first):\n",
            "  cmake/googletest.cmake:47 (FetchContent_Populate)\n",
            "  CMakeLists.txt:835 (include)\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Found Python3: /usr/local/bin/python (found version \"3.12.12\") found components: Interpreter\n",
            "-- Configuring cublas ...\n",
            "-- cuBLAS Disabled.\n",
            "-- Configuring cuBLAS ... done.\n",
            "-- Completed generation of library instances. See /content/cutlass/build/tools/library/library_instance_generation.log for more information.\n",
            "-- Found Python3: /usr/local/bin/python (found suitable version \"3.12.12\", minimum required is \"3.5\") found components: Interpreter\n",
            "-- Enable device reference verification in conv unit tests\n",
            "-- Configuring done (18.6s)\n",
            "-- Generating done (5.8s)\n",
            "-- Build files have been written to: /content/cutlass/build\n",
            "--2025-11-22 20:37:35--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/2023/week10_efficiency/kernel.cpp\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 851 [text/plain]\n",
            "Saving to: ‘kernel.cpp’\n",
            "\n",
            "kernel.cpp          100%[===================>]     851  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-22 20:37:35 (31.5 MB/s) - ‘kernel.cpp’ saved [851/851]\n",
            "\n",
            "--2025-11-22 20:37:35--  https://raw.githubusercontent.com/yandexdataschool/nlp_course/2023/week10_efficiency/kernel.cu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3003 (2.9K) [text/plain]\n",
            "Saving to: ‘kernel.cu’\n",
            "\n",
            "kernel.cu           100%[===================>]   2.93K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-22 20:37:36 (44.4 MB/s) - ‘kernel.cu’ saved [3003/3003]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QF47Yk_zuQSa",
        "outputId": "762f26fb-a768-42ef-b73b-9a091a2692b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.cpp_extension import load\n",
        "\n",
        "custom_kernel = load(name='custom_kernel', sources=['kernel.cpp', 'kernel.cu'], extra_include_paths=[r\"cutlass/include\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fEv4NL2uQSb"
      },
      "source": [
        "Usage: `output = custom_kernel.int8_matmul(X, Y)` and `output = custom_kernel.int4_matmul(X, Y)` compute $XY^T$ (same as `nn.functional.linear`).\n",
        "\n",
        "Notice that `int8_matmul` takes the normal `torch.int8` tensors, but int4_matmul expects `int4` values densely packed into `torch.uint8` tensors. This is exactly what we wrote **Dense Integer Packing** for. They have a <font color='red'>severe limitation</font>: the dimension of multiplication must be divisible by 16.\n",
        "\n",
        "Now you have to implement the quantized forward pass:\n",
        "\n",
        " $$\n",
        " \\begin{align}\n",
        "    XW^T &= (Q_x \\cdot scale_x + zero_x \\cdot scale_x)(Q_w \\cdot scale_w + zero_w \\cdot scale_w)^T =\\\\\n",
        "    &= (Q_x  + zero_x)(Q_w + zero_w)^T \\cdot (scale_x \\odot scale_w^T) =\\\\\n",
        "    &= (Q_xQ_w^T + Q_x zero_w^T + zero_x Q_w^T + zero_x zero_w^T) \\cdot (scale_x \\odot scale_w^T)\n",
        " \\end{align}\n",
        " $$\n",
        "\n",
        "because of the kernel limitations mentioned above, only the largest integer multiplication ($Q_xQ_w^T$) can be done in `int`. Perform the other ones in `float`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"NousResearch/Llama-3.2-1B\"\n",
        "\n",
        "def get_llama_model_and_tokenizer():\n",
        "    model = LlamaForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        device_map=\"cpu\", dtype=torch.float16,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    model.config.pad_token_id = model.config.eos_token_id\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "yayC4hD7tjya"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPUs, Throughput and Quantization"
      ],
      "metadata": {
        "id": "GpK5PF-P9WNU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chFnB1GN-Jgu"
      },
      "source": [
        "Torch natively supports `int8`, but not `int4`. For the most part, we will `torch.uint8` to represent tensors quantized to *4 bits*. We encoded each *4-bit* value with an *8-bit* value, using twice as much memory as we really needed. We did this because `torch` lacks support for 4-bit tensors. However, we never performed any native operations in *8 bits*; we always converted it to `torch.float16` first. That means we can design a more efficient way to encode *4-bit* tensors and convert to and from it.\n",
        "\n",
        "Your task is to implement these conversions, converting *8-bit* tensors containing *4-bit* values (the way we used to store quantized weights) to and from smaller *8-bit* tensor, utilizing the whole range of values. Moreover, you'll have to do it in a way such that memory representation of contiguous arrays wouldn't change. That is, adjacent columns get squashed together.\n",
        "\n",
        "**Task (1.0pt):** Implement dense *int4*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MNprlCWn-Jgw"
      },
      "outputs": [],
      "source": [
        "def dense_pack_4_8(x: Tensor) -> Tensor:\n",
        "    \"\"\"Constructs a densely packed int tensor\n",
        "    Args:\n",
        "        x (Tensor): uint8 with uint4 values range\n",
        "\n",
        "    Returns:\n",
        "        Tensor: twice as small uint8 tensor with uint8 values range\n",
        "    \"\"\"\n",
        "    x = x.clone().detach()\n",
        "    return x[...,::2] * 16 + x[..., 1::2]\n",
        "\n",
        "def dense_unpack_4_8(x: Tensor) -> Tensor:\n",
        "    \"\"\"Deconstructs a densely packed int tensor\n",
        "    Args:\n",
        "        x (Tensor): uint8 tensor with uint8 values range\n",
        "\n",
        "    Returns:\n",
        "        Tensor: twice as large int8 tensor with uint4 values range\n",
        "    \"\"\"\n",
        "    x = x.clone().detach()\n",
        "    res = torch.empty(x.shape[:-1] + (x.size(-1) * 2,), device=x.device, dtype=torch.uint8)\n",
        "    res[..., ::2] = x // 16\n",
        "    res[..., 1::2] = x % 16\n",
        "    return res\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4AZQO84e-Jgw",
        "outputId": "2a15a612-b869-4ea9-9775-06972e2b6981",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed!\n"
          ]
        }
      ],
      "source": [
        "# Testing your code\n",
        "\n",
        "quantized_x = torch.randint(0, 16, (512 * 1024,)).reshape(512, 1024).float()\n",
        "dense_quantized_x = dense_pack_4_8(quantized_x)\n",
        "undense_quantized_x = dense_unpack_4_8(dense_quantized_x)\n",
        "\n",
        "assert dense_quantized_x.shape == (512, 512)\n",
        "assert torch.all(undense_quantized_x == quantized_x)\n",
        "assert torch.all(dense_unpack_4_8(dense_pack_4_8(quantized_x[:8,:8])) == dense_unpack_4_8(dense_pack_4_8(quantized_x)[:8,:4])), \"Adjacent values shall be packed\"\n",
        "print(\"All tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can benchmark the quantized GEMM kernels to estimate the speedups:"
      ],
      "metadata": {
        "id": "VZ0liP9hDG1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from triton.testing import do_bench\n",
        "\n",
        "HIDDEN_SIZE = 4096\n",
        "NUM_REPEATS = 1024\n",
        "\n",
        "B_fp16 = torch.randint(0, 16, (HIDDEN_SIZE, HIDDEN_SIZE), dtype=torch.float16, device=\"cuda\")\n",
        "B_int8 = B_fp16.to(torch.int8)\n",
        "B_int4 = dense_pack_4_8(B_int8)\n",
        "\n",
        "fp16_latencies = {}\n",
        "int8_latencies = {}\n",
        "int4_latencies = {}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for BATCH_SIZE in tqdm([1, 2, 4, 8, 16, 32, 64, 128, 256, 512], desc=\"Iterating BATCH_SIZE\"):\n",
        "        A_fp16 = torch.randint(0, 16, (BATCH_SIZE, HIDDEN_SIZE), dtype=torch.float16, device=\"cuda\")\n",
        "        A_int8 = A_fp16.to(torch.int8)\n",
        "        A_int4 = dense_pack_4_8(A_int8)\n",
        "\n",
        "        fp16_latencies[BATCH_SIZE] = do_bench(lambda: torch.nn.functional.linear(A_fp16, B_fp16, None), rep=500)\n",
        "        int8_latencies[BATCH_SIZE] = do_bench(lambda: custom_kernel.int8_matmul(A_int8, B_int8), rep=500)\n",
        "        int4_latencies[BATCH_SIZE] = do_bench(lambda: custom_kernel.int4_matmul(A_int4.view(torch.uint8), B_int4.view(torch.uint8)), rep=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c063897199da419aaabfd427c1c2dad9",
            "9dd5fb4871994810bc1090b7dc28ae9c",
            "635b4af413e2400db1f5a3fea54de9ca",
            "7bad5b4030fb40cc839ee31c04952bde",
            "53435bc10af34cf6b157a5113e485811",
            "4ab3b751044843159bff1bf4f9deca5f",
            "214af78205de4dc2a9254bd58689b3bb",
            "84376e467af44c678d6bd5d2501f25f4",
            "f1d25633c7ad458f82e41c2ff80f22c0",
            "44670b0fc90c4d46a97e4e9e72690363",
            "bf7023e475ac4d1e88b1952ba49af6a7"
          ]
        },
        "id": "iEL-EAVw9Zoo",
        "outputId": "536554e1-deba-42c3-cd93-f40a0af2a0db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Iterating BATCH_SIZE:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c063897199da419aaabfd427c1c2dad9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(fp16_latencies.keys(), [key/val for key, val in fp16_latencies.items()], label=\"FP16\")\n",
        "plt.plot(int8_latencies.keys(), [key/val for key, val in int8_latencies.items()], label=\"INT8\")\n",
        "plt.plot(int4_latencies.keys(), [key/val for key, val in int4_latencies.items()], label=\"INT4\")\n",
        "# plt.xscale(\"log\")\n",
        "\n",
        "plt.xlabel(\"Batch size\")\n",
        "plt.ylabel(\"Troughput, elements per second\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "d1AYFgonBSUp",
        "outputId": "92133d66-8f79-4fdf-d2c6-6c44f6727c60"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's easy to see that the speedup is ~2x for INT8 and ~4x for INT4 compared to FP16 for all batch sizes!"
      ],
      "metadata": {
        "id": "gf41qwHIDLL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speculative Decoding"
      ],
      "metadata": {
        "id": "Wj8ikoVEtDlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Throughput Benchmarking"
      ],
      "metadata": {
        "id": "eOpNnZG84cTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = get_llama_model_and_tokenizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311,
          "referenced_widgets": [
            "95cbb03a29ac445d888b96352d3be3e5",
            "15bf3854c4cb4d95b77752a322750492",
            "89385b373b924530ab7fbbc3746d2e11",
            "9520be933e0c444d9f7057e391222f1f",
            "19997800a9bf449b9161684d423c00c8",
            "17168fc1f8c244288bd17e5ab29f3f1b",
            "19509b2ea4e947c3bc07501e3e76fe5a",
            "2a5c54a1f4eb4376bc2968a98c6722b9",
            "fc0d4a85c37d4c28af2f3d94dc374a98",
            "ba4c72f900554e7f96c70447f05ad759",
            "5110b0dc0c7344e5b83b6f69034f445b",
            "31fc111c34b74ae4ad65a86056652907",
            "50f8a893ad0c43288f39f0edfdf32162",
            "f10e8d3cbb1845e19f687978ad26f2c3",
            "3726a6384d7449c7b0a3834c2a0c2424",
            "f41b50bd4a764c2984978027c1afff6e",
            "49f4dcb85f5748a2a29193e70b65b661",
            "84ca9d1501e843a79be8c93474b6130a",
            "75c76f5d9ee746b699d73b7e20185854",
            "c4e2dcd79eeb4947b9d7d1d079f8b752",
            "be988790010f48a5a1ee73409772d101",
            "a770f93162d74637be238192e77b5a18",
            "fe91014155e64612863f7a1d2ffdaa23",
            "207c7bb9d7754d068019ca3d9015f1a5",
            "a869f6f9a3344fa2a85202c6288eaf0d",
            "a3c6933c353b443d826e0399f59e273c",
            "2058b7f1b30a4551a49461d6b6a6b033",
            "852ed38469864b24a544506f4ac04111",
            "427209bdd0224f38922702d7c6d470fd",
            "9a638393987c4894acdc346d2c1ae04c",
            "3c85d05e373e4fb797ebc4dd46253edc",
            "f42719e8383243ba9c9648eb31b3930b",
            "7888f1e3a61d460fa74f0ddcf957e9ee",
            "479feacabcf441db943d8be57e805fdd",
            "dac627239fe749019cf220f05beb19d7",
            "f4fd1018467a4d7cae32b1a31bcaa302",
            "5ae71255c7834ef08a16cb8eca8adefa",
            "83355ce9d5b24be182aeeebb2771636a",
            "bba13416cb4042cbbdfc40cd31a22459",
            "11db54bdbf884b1c9ef1b470200ba22e",
            "c89ac7b561244b369248eb98093fb710",
            "52967c4fc74848c28f2b50acd242045b",
            "55553a575ffb4434a033c76db8895e85",
            "31da59e2aa4d425990fc9be032522409",
            "65c734050521462a95a2136130323d23",
            "31bb6fdee1484ba3a1a79c9450722b4c",
            "431c8c3fdb884d7ba231bda49ddae8c2",
            "1d79e8641f7c43728316fb3ceb98927b",
            "075a048ab4a9452a8e5ac27302e243cc",
            "8fb1b2d01f234bae97e9b53cbc007c55",
            "06be226b70f044c0b66c521d379d7d6c",
            "f545db5976b34e689952054c628f6880",
            "966a6bfdc93c4dba8c5aef2db95f205d",
            "c67354be57f641e19d0b4f25a471c472",
            "87fc35e089f548b1a993047b30fdb121",
            "8e57806acbf14d23aca16c1559621258",
            "1602613a80ae4822af657eaa4526ba1d",
            "548f622055a646ef8fb4c9ba8cc29c9e",
            "3857a29be8154b54ab568a808dd17cec",
            "e5054d2bf38346ffa8797c7df05a92b7",
            "05633451b86647608b7e46d6db4a9dbc",
            "8436554294994c218e30e9807636b4f8",
            "78f61b38bd1a42468a13aa57b7f17ab7",
            "daa811b3404c4b8084104ef4241a0057",
            "daed8d1eb3894beeabab2d2234a7295c",
            "38a8e15d5907485cb843d056f83bdc46"
          ]
        },
        "id": "LGSWYgZ5tGTY",
        "outputId": "1efb376b-c211-449b-a754-74a9897e47de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95cbb03a29ac445d888b96352d3be3e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31fc111c34b74ae4ad65a86056652907"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/186 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe91014155e64612863f7a1d2ffdaa23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "479feacabcf441db943d8be57e805fdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65c734050521462a95a2136130323d23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e57806acbf14d23aca16c1559621258"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tABKQ69wqKk6"
      },
      "source": [
        "**Compile model forward for more accurate benchmarks**\n",
        "\n",
        "`transformers` is not a very efficient inference engine because of high python overhead and almost no kernel optimization.\n",
        "\n",
        "However, with `PyTorch` `v2.0.0`, [`torch.compile`](https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html) was introduced. This feature allows for capturing, isolating and optimizing CUDA runtime in `PyTorch`. Using this feature, we can effectively eliminate almost all python overhead and optimize the kernels.\n",
        "\n",
        "Starting with [`transformers` `v4.44.0`](https://github.com/huggingface/transformers/releases/tag/v4.44.0), this feature is integrated with `transformers` text generation utils end-to-end. However, for simplicity, we'll apply it to the forward pass of the model specifically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-QLsL7m0qKk6"
      },
      "outputs": [],
      "source": [
        "model = model.to(\"cuda\")\n",
        "model.forward = torch.compile(\n",
        "    model.forward,          # the function call to compile\n",
        "    fullgraph=True,         # Compile all the CUDA kernels into a single entity\n",
        "    mode=\"reduce-overhead\", # Optimize for speed\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x5ojJbrqKk7"
      },
      "source": [
        "**Benchmark forward passes with different seq_len**\n",
        "\n",
        "Run the following cell 2+ times. The first time is slow because that's when the compilation is taking place.\n",
        "\n",
        "The following runs are much faster.\n",
        "\n",
        "(EXTRA: run this cell without compiling to measure scompilation speedup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y_geHUkqKk7",
        "outputId": "7180a9b8-28f5-4e43-bade-dd8ed46fd63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 tokens: 88.22 passes/s\n",
            "2 tokens: 81.04 passes/s\n",
            "4 tokens: 80.07 passes/s\n",
            "8 tokens: 78.49 passes/s\n",
            "16 tokens: 73.04 passes/s\n",
            "32 tokens: 64.66 passes/s\n",
            "64 tokens: 61.04 passes/s\n"
          ]
        }
      ],
      "source": [
        "from time import perf_counter\n",
        "\n",
        "NUM_REPEATS = 100\n",
        "\n",
        "throughpus = {}\n",
        "\n",
        "for seq_len in [1, 2, 4, 8, 16, 32, 64]:\n",
        "    input_ids = torch.randint(0, tokenizer.vocab_size, (1, seq_len)).to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(10):\n",
        "            model(\n",
        "                input_ids,\n",
        "                use_cache=False,\n",
        "            )\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        start = perf_counter()\n",
        "        for _ in range(NUM_REPEATS):\n",
        "            model(\n",
        "                input_ids,\n",
        "                use_cache=False,\n",
        "            )\n",
        "            torch.cuda.synchronize()\n",
        "        end = perf_counter()\n",
        "    throughpus[seq_len] = NUM_REPEATS * seq_len / (end - start)\n",
        "    print(f\"{seq_len} tokens: {NUM_REPEATS / (end - start):.2f} passes/s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-qz7ahOqKk8"
      },
      "source": [
        "As we can see, the forward pass speed almost doesn't depend on the number of tokens passed through the model up to around **16** tokens at a time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PwAeHLbAqKk9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "4608e413-da3f-40fd-f62c-6b66d1f1d90a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Troughput, tokens per second')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(throughpus.keys(), throughpus.values())\n",
        "plt.xscale(\"log\")\n",
        "plt.yscale(\"log\")\n",
        "\n",
        "plt.xlabel(\"Tokens in pass\")\n",
        "plt.ylabel(\"Troughput, tokens per second\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "mngHDFBJyBRn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFIT6AmUqKk9"
      },
      "source": [
        "## Speculative Decoding\n",
        "\n",
        "As a baseline, we'll generate hypotheses using a very simple bigram model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd7JF2jQqKk-"
      },
      "source": [
        "### Load the Data\n",
        "\n",
        "We'll use the [wikitext2](https://paperswithcode.com/dataset/wikitext-2) dataset as a sample of natural language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rk8KcWC4qKk-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258,
          "referenced_widgets": [
            "c993d0bbaaba41fe8e601b5b1d178fc7",
            "9204a05dca284862b9f56556b7d50ec3",
            "6efcff50dcc74a1cbe5ff7532a7368ad",
            "0bc7c0482b8a4cdf9f92cba70fcb4f5c",
            "cc59e4c920564fb99ac0e41a0bcb89ed",
            "6d4bd0005a5d4ee3ac09878f199fbba2",
            "7fa665f428f44157adbe8fe2892acb2b",
            "5da01a3dea5b4bf69c4a401c6418376e",
            "6a223a03238949fd8b13e462ed1c75c2",
            "9a9c27c09cd94c4fa74ced6ad98f7a68",
            "9327acabe1394fdbbfb5baceb36014b0",
            "6c87b8cb45ed47f7b9889da6812e6621",
            "c275fe230df84ba5835b0fff72ad52fa",
            "6014f22307214db19aeb7220c15319f3",
            "44b4f390a015471099877615341f268c",
            "26b9afd36abd43a3bab37af1cf50174f",
            "53f4be8f9c5f4a96bbf8df9087650363",
            "6e4579ba75154502b01a63f12eeb126b",
            "ad7e7e73fa594489bb2a91cc2cb904c4",
            "1bf185d52d864e5787d3ce6ebc6d1994",
            "9f64bb86c8e14bb2aa8e73e5512bd5ba",
            "43c9861f3f4b401fbca3fbc4ca3903f8",
            "cdf0fa43de30409d839b890c37799e24",
            "11dcbf8e53c84b4b9e67ad0dc83c141e",
            "354785540e8c4bee81344dee4e183b8a",
            "6787773de99d4cc484329167140b95fb",
            "59773df278a0432dbd26dcb0be519208",
            "9110795d478c4951a061f46178c52ae0",
            "6e5b78e39de84b4f9dd8b7f28b3fb2d5",
            "ed8957d6f01e4853921832026c0c60d8",
            "87902293a18744a6bb09d21329c2a7a6",
            "45bf66463ee54ec3b75f4b638e58cd97",
            "986f4fc7e48548ba86af0b9b07942f21",
            "7655a8335c0e420f849acab758829244",
            "2d22582216834dc0b1e47130662bbd17",
            "db67e2be7cc7430a9719d575311c25fe",
            "87217e1ec47b4d0493de22d340b79971",
            "66f46daf054446ff84b0ce15b1d4a3fe",
            "2cf35ab59b59473badfa2f01e3c295f0",
            "0cf5618a902646839ccb497932862c65",
            "8d64e42358784333b0e0234f00be3c08",
            "3bd182c79c844405b9bb641af408e21a",
            "506be2f2bcfd4eaabe5aee72afd840af",
            "71173630c8304831bf5e21a6cafaa1fa",
            "0c41d071a80249ac8e5c3a1b2d6a76c0",
            "d150ff9a0c644bfa888e4d56082232fd",
            "4073dbfa26044cb29269164441731b28",
            "ad9085d03275431b96c4ccf17535a7fb",
            "2331db39933f4e2482aed65c821c3fcc",
            "b65466a57ad041e182cbc5060a75e8e1",
            "ef48b2c19d0b4a0eae11da3cb8f14df2",
            "314e58f4b4bd4d189ff265bf6bf26173",
            "ce0c8c60b7fa498e8426774b61f1cdd5",
            "2cc7bf93b7294be49cd9dbce4305cb29",
            "9f6e562d526041f1b9127cfb2a7e6d79",
            "3109995be6f945d88619cb69fc071ff7",
            "fd753f0774b246bdbba9fbe3fe67bc10",
            "03d0b0efa3244d988cd8ecec9ca536d2",
            "124a1b9ea21f4f72a09657bcf68c839e",
            "02b08e9f4d6042829b0628b032ee1a09",
            "36dbee7bc4a1462682ebe6ee0cdf6110",
            "189853cf6aba410d833cd99f2b2c6771",
            "66c4c7d7393443b9b885896b1eb4f931",
            "7c578567f5bc4c3eb0fdce60ce0aeceb",
            "e0f9648951304be78e6c30b61ed9baf4",
            "e2626d6abe8b4d4ea23fc56643ae79bc",
            "9582dd2e791a4e0a8a77ae0a0f7b3489",
            "1446e858c82e4d529661191d9e22701f",
            "dee404200b7e448da49d7ecb992ca44a",
            "1ca2a3ec43b3450d845b5ba2043e311e",
            "8b39389aded949ad8eb393aa4543cf23",
            "88b9fc2a34aa426d95b095c0939ebc42",
            "8686ac8daa3b44b8ad562f37f32289df",
            "c0726f1576eb44d7b4f623d82e239856",
            "89cc6d30d6e0416e8997b57042499df9",
            "7cc4c476b9b9445da8011c751ea83adf",
            "7873993f209b4ada8f23ed79927824ff"
          ]
        },
        "outputId": "b8bb191b-9b3a-4304-a8df-97231884d9b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c993d0bbaaba41fe8e601b5b1d178fc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "wikitext-2-raw-v1/test-00000-of-00001.pa(…):   0%|          | 0.00/733k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c87b8cb45ed47f7b9889da6812e6621"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "wikitext-2-raw-v1/train-00000-of-00001.p(…):   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdf0fa43de30409d839b890c37799e24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "wikitext-2-raw-v1/validation-00000-of-00(…):   0%|          | 0.00/657k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7655a8335c0e420f849acab758829244"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c41d071a80249ac8e5c3a1b2d6a76c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3109995be6f945d88619cb69fc071ff7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9582dd2e791a4e0a8a77ae0a0f7b3489"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2436214 > 131072). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "SEED = 0\n",
        "\n",
        "def get_wikitext2(seed, seqlen, nsamples=64):\n",
        "    traindata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='train')\n",
        "    testdata = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    train_input_ids = tokenizer(\"\\n\\n\".join(traindata['text']), return_tensors='pt').input_ids\n",
        "    random.seed(seed)\n",
        "    train_batch = []\n",
        "    for _ in range(nsamples):\n",
        "        i = random.randint(0, train_input_ids.shape[1] - seqlen - 1)\n",
        "        j = i + seqlen\n",
        "        inp = train_input_ids[:, i:j]\n",
        "        tar = inp.clone()\n",
        "        tar[:, :-1] = -100\n",
        "        train_batch.append(inp[0])\n",
        "\n",
        "    test_input_ids = tokenizer(\"\\n\\n\".join(testdata['text']), return_tensors='pt').input_ids\n",
        "    test_input_ids = test_input_ids[:, :(test_input_ids.shape[1] // seqlen) *  seqlen]\n",
        "    test_input_ids = test_input_ids.reshape(test_input_ids.shape[1] // seqlen, seqlen)\n",
        "\n",
        "    return torch.stack(train_batch), test_input_ids\n",
        "\n",
        "train_batch, test_input_ids = get_wikitext2(SEED, 8192)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K-tFOxyqKk-"
      },
      "source": [
        "**Task (1.0pt):** Build a bigram model\n",
        "\n",
        "Using sequences from `train_batch`, build a bigram model for predicting `n` tokens into the future.\n",
        "\n",
        "WARNING: torch.Tensors have weird interactions with dicts and Counters. use `.item()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Anchr3_TqKk-"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm, trange\n",
        "\n",
        "from typing import Mapping\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "def build_next_token_array(train_data, vocab_size: int=128256, default_next_token: int=220) -> Mapping[int, int]:\n",
        "    \"\"\"\n",
        "    Builds an array mapping each token in the vocabulary to its most likely next token based on training data.\n",
        "\n",
        "    Args:\n",
        "        train_data (torch.Tensor): Array of training data tokens.\n",
        "        vocab_size (int): The size of the vocabulary.\n",
        "        default_next_token (int): Default token to use if no next token can be determined.\n",
        "\n",
        "    Returns:\n",
        "        Mapping[int, int]: Array where each index represents a token and the value at that index is the most likely next token.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE>>>>>>>>>\n",
        "    # Step 1: Prepare the Data\n",
        "    # Convert tensor to a list of integers for easier processing\n",
        "    if isinstance(train_data, torch.Tensor):\n",
        "        tokens = train_data.flatten().cpu().tolist()\n",
        "    else:\n",
        "        tokens = train_data.flatten() if hasattr(train_data, 'flatten') else train_data\n",
        "\n",
        "    # Step 2: Create Pairs and Count Occurrences\n",
        "    # Count bigram occurrences: (current_token, next_token) -> count\n",
        "    bigram_counts = defaultdict(lambda: defaultdict(int))\n",
        "    for i in range(len(tokens) - 1):\n",
        "        current_token = int(tokens[i])\n",
        "        next_token = int(tokens[i + 1])\n",
        "        bigram_counts[current_token][next_token] += 1\n",
        "\n",
        "    # Step 3: Build Mapping from Current Token to Next Token Counts\n",
        "    # Step 4: Determine the Most Likely Next Token\n",
        "    # For each token, find the next token with maximum count\n",
        "    next_tokens_array = [default_next_token] * vocab_size\n",
        "\n",
        "    for current_token in range(vocab_size):\n",
        "        if current_token in bigram_counts:\n",
        "            # Find the next token with maximum count\n",
        "            next_token_counts = bigram_counts[current_token]\n",
        "            if next_token_counts:\n",
        "                most_likely_next = max(next_token_counts.items(), key=lambda x: x[1])[0]\n",
        "                next_tokens_array[current_token] = most_likely_next\n",
        "\n",
        "    # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "    return next_tokens_array\n",
        "\n",
        "def speculate_bigram(input_ids: torch.Tensor, position: int, n: int, next_tokens_array: Mapping[int, int]) -> int:\n",
        "    \"\"\"\n",
        "    Generates a speculative sequence by predicting next tokens in a sequence using a bigram model.\n",
        "\n",
        "    Args:\n",
        "        input_ids (torch.Tensor): Tensor of input token IDs.\n",
        "        position (int): Position in the sequence to begin speculation.\n",
        "        n (int): Number of tokens to generate.\n",
        "        next_tokens_array (Mapping[int, int]): Mapping of tokens to their most likely next token.\n",
        "\n",
        "    Returns:\n",
        "        int: Number of tokens generated.\n",
        "    \"\"\"\n",
        "    for i in range(n):\n",
        "        hypo_next_token = next_tokens_array[input_ids[0, position - 1].item()]\n",
        "        input_ids[0, position] = hypo_next_token\n",
        "        position += 1\n",
        "    return n\n",
        "\n",
        "\n",
        "NEXT_TOKEN_WIKI2 = build_next_token_array(train_batch.flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZP5SyfXqKk_"
      },
      "source": [
        "**Task (2.0pt):** Implement greedy sequential speculative decoding:\n",
        "\n",
        "You're given a prototype of the function that generate a token sequence greedily by speculating `n` tokens into the fulure and verifying those tokens.\n",
        "\n",
        "Your task is to:\n",
        " * Correctly fill a hypothesis inplace (using `speculate_fn`)\n",
        " * Pass the hypothesis through the model (with correct `past_key_values`)\n",
        " * Find where the hypothesis diverges.\n",
        " * Update the current position in the generation, as well as the number of forward pass calls."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = get_llama_model_and_tokenizer()\n",
        "model = model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "yiu9ItbT0Wvs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjF97B3gqKk_",
        "outputId": "5a247921-6630-45ea-c747-844934105ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HIT: ' a'->' a'\n",
            "HIT: ' of the'->' of the'\n",
            "HIT: ' States'->' States'\n",
            "HIT: ' the'->' the'\n",
            "HIT: ' the'->' the'\n",
            "HIT: ' Ocean'->' Ocean'\n",
            "HIT: ' the'->' the'\n",
            "HIT: ' to'->' to'\n",
            "HIT: ' of'->' of'\n",
            "HIT: ' a'->' a'\n",
            "HIT: ' and'->' and'\n",
            "HIT: ' a'->' a'\n",
            "HIT: ' of the'->' of the'\n",
            "HIT: ' States'->' States'\n",
            "HIT: ' the'->' the'\n",
            "Tokens per forward pass: 1.1904761904761905\n",
            "\n",
            "<|begin_of_text|>The Pacific Northwest is a region of the United States that includes the states of Washington, Oregon, and Idaho. It is known for its natural beauty, including the Cascade Mountains, the Pacific Ocean, and the Columbia River. The region is also home to a diverse population of people, including Native Americans, Asians, and Europeans. The Pacific Northwest is a popular tourist destination, with many people visiting the region to enjoy its natural beauty and cultural attractions.\n",
            "The Pacific Northwest is a region of the United States that includes the\n"
          ]
        }
      ],
      "source": [
        "from transformers import StaticCache\n",
        "\n",
        "\n",
        "def truncate_past_key_values(past_key_values, position):\n",
        "    \"\"\"\n",
        "    Truncates the past key and value caches at a specific position. `transformers`-specific stuff. Might change with their next update.\n",
        "\n",
        "    Args:\n",
        "        past_key_values (object): Object containing key and value caches for each layer.\n",
        "        position (int): Position from which to truncate the caches.\n",
        "    \"\"\"\n",
        "    for layer in past_key_values.layers:\n",
        "        layer.keys[:,:,position - 1:] = 0.0\n",
        "        layer.values[:,:,position - 1:] = 0.0\n",
        "\n",
        "\n",
        "def generate_speculative(model, tokenizer, num_tokens_to_generate: int, speculate_fn: callable, max_speculated_len: int=128, initial_prompt: str=\"The Pacific\", verbose: bool=False):\n",
        "    \"\"\"\n",
        "    Generates text using speculative decoding, a technique that combines conventional forward passes with speculative predictions to reduce computation by hypothesizing multiple tokens at each step.\n",
        "\n",
        "    Args:\n",
        "        model (transformers.PreTrainedModel): The language model used to generate text.\n",
        "        tokenizer (transformers.PreTrainedTokenizer): Tokenizer corresponding to the model for encoding and decoding text.\n",
        "        num_tokens_to_generate (int): The number of tokens to generate in total.\n",
        "        speculate_fn (callable): A function that generates speculative tokens based on the input IDs and current position.\n",
        "            This function takes `input_ids` and `position` as arguments and returns the number of tokens speculated.\n",
        "        max_speculated_len (int, optional): The maximum length of speculative tokens allowed in a single step. Defaults to 128.\n",
        "        initial_prompt (str, optional): The starting prompt for text generation. Defaults to \"The Pacific\".\n",
        "        verbose (bool, optional): If True, prints debugging information about successful speculative predictions. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The generated sequence of input IDs up to the generated position.\n",
        "        int: The number of forward passes required for generation, which can be used to assess efficiency.\n",
        "\n",
        "    Example:\n",
        "        >>> output, forward_passes = generate_speculative(\n",
        "        ...     model,\n",
        "        ...     tokenizer,\n",
        "        ...     num_tokens_to_generate=100,\n",
        "        ...     speculate_fn=lambda input_ids, position: fill_hypothesis(input_ids, position, n=2, next_tokens_array=next_tokens_array),\n",
        "        ...     verbose=True\n",
        "        ... )\n",
        "        >>> print(\"Generated Text:\", tokenizer.decode(output))\n",
        "        >>> print(\"Tokens per forward pass:\", 100 / forward_passes)\n",
        "\n",
        "    Notes:\n",
        "        - Speculative decoding reduces the number of model passes by hypothesizing tokens using the `speculate_fn` function. The actual model output is used to verify these hypotheses, allowing efficient token generation.\n",
        "        - If verbose mode is enabled, it will display speculative matches as they occur.\n",
        "    \"\"\"\n",
        "\n",
        "    # Encode the initial prompt and get input IDs, then move them to the GPU\n",
        "    prompt_ids = tokenizer(initial_prompt, return_tensors=\"pt\", truncation=True).input_ids.to(\"cuda\")\n",
        "    position = prompt_ids.shape[1]  # Initial position for the prompt\n",
        "\n",
        "    # Calculate the maximum cache length to accommodate generated tokens and speculative tokens\n",
        "    max_cache_len = num_tokens_to_generate + position + max_speculated_len\n",
        "    # Initialize the cache for past key values with model configuration, setting cache size and device\n",
        "    past_key_values = StaticCache(config=model.config, max_batch_size=1, max_cache_len=max_cache_len, device=\"cuda\", dtype=torch.float16)\n",
        "    # Allocate space for input IDs and cache positions on the GPU\n",
        "    input_ids = torch.zeros((1, max_cache_len), device=\"cuda\", dtype=torch.long)\n",
        "    # Fill in the initial prompt\n",
        "    input_ids[0, :position] = prompt_ids[0, :position]\n",
        "    with torch.no_grad():  # Disable gradients for inference\n",
        "        # Pre-fill cache with the prompt to start the model's internal state\n",
        "        past_key_values = model(input_ids[:, :position], past_key_values=past_key_values).past_key_values\n",
        "\n",
        "        forward_passes = 0  # Track number of forward passes\n",
        "        tokens_generated = 0  # Track number of tokens generated\n",
        "        while tokens_generated < num_tokens_to_generate:\n",
        "            # Adjust cache by removing outdated values to avoid memory overflow\n",
        "            truncate_past_key_values(past_key_values, position)\n",
        "            # Speculate the next few tokens based on current position\n",
        "            num_tokens_speculated = speculate_fn(input_ids, position)  # Number of tokens hypothesized\n",
        "            # YOUR CODE HERE>>>>>>>>>\n",
        "            output = model(\n",
        "                input_ids[:, position - 1 : position + num_tokens_speculated], past_key_values=past_key_values\n",
        "            )\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "            past_key_values = output.past_key_values  # Update the cache with new predictions\n",
        "\n",
        "            # Extract predicted tokens and the speculative tokens for comparison\n",
        "            # YOUR CODE HERE>>>>>>>>>\n",
        "            pred_tokens = input_ids[:, position:position + num_tokens_speculated]\n",
        "            real_tokens = output.logits.argmax(dim=-1)\n",
        "            match_len = 0\n",
        "            for i in range(min(len(pred_tokens[0]), len(real_tokens[0]))):\n",
        "                if pred_tokens[0][i] == real_tokens[0][i]:\n",
        "                    match_len += 1\n",
        "                else:\n",
        "                    break\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "            # Optionally, print successful speculative predictions\n",
        "            if verbose and match_len > 0:\n",
        "                print(\n",
        "                    f\"HIT: '{tokenizer.decode(pred_tokens[0, :match_len])}'->'{tokenizer.decode(real_tokens[0, :match_len])}'\"\n",
        "                )\n",
        "\n",
        "            # Copy matched tokens to the input IDs array\n",
        "            # YOUR CODE HERE>>>>>>>>>\n",
        "            input_ids[:, position:position + match_len] = pred_tokens[:, :match_len]\n",
        "            input_ids[:, position + match_len] = real_tokens[:, match_len]\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "            # Update the position, tokens generated count, and forward passes\n",
        "            # YOUR CODE HERE>>>>>>>>>\n",
        "            position += match_len + 1\n",
        "            forward_passes += 1\n",
        "            tokens_generated += match_len + 1\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "    return input_ids[0, :position + num_tokens_to_generate - tokens_generated], forward_passes\n",
        "\n",
        "\n",
        "NUM_TOKENS_TO_GENERATE = 100\n",
        "\n",
        "# Call the function with parameters and lambda function for speculative decoding\n",
        "output, forward_passes = generate_speculative(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    NUM_TOKENS_TO_GENERATE,\n",
        "    speculate_fn=lambda input_ids, position: speculate_bigram(input_ids, position, n=2, next_tokens_array=NEXT_TOKEN_WIKI2),\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Display metrics and the decoded output\n",
        "print(f\"Tokens per forward pass: {NUM_TOKENS_TO_GENERATE / forward_passes}\\n\")\n",
        "print(tokenizer.decode(output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vSbqLx7lqKlA",
        "collapsed": true,
        "outputId": "919d8644-9786-497a-82b6-a0f579138ee2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed\n"
          ]
        }
      ],
      "source": [
        "output0, n0 = generate_speculative(model, tokenizer, NUM_TOKENS_TO_GENERATE, speculate_fn=lambda input_ids, position: speculate_bigram(input_ids, position, 0, NEXT_TOKEN_WIKI2), verbose=False)\n",
        "output1, n1 = generate_speculative(model, tokenizer, NUM_TOKENS_TO_GENERATE, speculate_fn=lambda input_ids, position: speculate_bigram(input_ids, position, 1, NEXT_TOKEN_WIKI2), verbose=False)\n",
        "output2, n2 = generate_speculative(model, tokenizer, NUM_TOKENS_TO_GENERATE, speculate_fn=lambda input_ids, position: speculate_bigram(input_ids, position, 2, NEXT_TOKEN_WIKI2), verbose=False)\n",
        "output4, n4 = generate_speculative(model, tokenizer, NUM_TOKENS_TO_GENERATE, speculate_fn=lambda input_ids, position: speculate_bigram(input_ids, position, 4, NEXT_TOKEN_WIKI2), verbose=False)\n",
        "\n",
        "try:\n",
        "    assert n0 == NUM_TOKENS_TO_GENERATE, \"Model that doesnt' speculate does exatcly one forward pass per token\"\n",
        "    assert n4 <= n2 and n2 <= n1 and n1 < n0, \"It's very unlikely that the performance decreases with stronger speculation\"\n",
        "    assert (output1[:40] == output0[:40]).all(), \"The outputs diverge too early. Maybe ignore if really sure it's okay\"\n",
        "    print(\"All tests passed\")\n",
        "except AssertionError as e:\n",
        "    print(\"Error occured. Generated texts:\\n\")\n",
        "    print(*tokenizer.batch_decode([output0, output1, output2, output4]), sep=\"\\n\", end=\"\\n\\n\")\n",
        "    raise e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIplTHc7qKlA",
        "outputId": "e270cd4d-a588-4872-c1fa-e5affea0e00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speculate length 0: 1.00 tokens per forward pass\n",
            "Speculate length 1: 1.16 tokens per forward pass\n",
            "Speculate length 2: 1.19 tokens per forward pass\n",
            "Speculate length 3: 1.19 tokens per forward pass\n",
            "Speculate length 4: 1.19 tokens per forward pass\n",
            "Speculate length 5: 1.19 tokens per forward pass\n",
            "Speculate length 6: 1.19 tokens per forward pass\n"
          ]
        }
      ],
      "source": [
        "for speculate_length in [0, 1, 2, 3, 4, 5, 6]:\n",
        "    _, num_passes = generate_speculative(model, tokenizer, NUM_TOKENS_TO_GENERATE, speculate_fn=lambda input_ids, position: speculate_bigram(input_ids, position, speculate_length, NEXT_TOKEN_WIKI2), verbose=False)\n",
        "    print(f\"Speculate length {speculate_length}: {NUM_TOKENS_TO_GENERATE / num_passes:.2f} tokens per forward pass\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T48EpfDmqKlA"
      },
      "source": [
        "It appears the bigram model doesn't improve above `2`. That is because it's very unlikely that a bigram model outputs a long meaningful sequence. For better models and approaches, read this:\n",
        " - https://arxiv.org/abs/2503.01840\n",
        " - https://arxiv.org/abs/2305.09781\n",
        " - https://arxiv.org/abs/2406.02532"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQkjY8Jp1OpH"
      },
      "source": [
        "# Quantizing Matrices Row-Wise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzEoWTNMi62K"
      },
      "source": [
        "### Basic Quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFG1FDsVi62L"
      },
      "source": [
        "**Mapping the values to the allowed range**\n",
        "\n",
        "Quantization is the process of mapping input values from a large set to output values in a smaller set. For instance, if we consider 4-bit\n",
        "quantization, our values are represented by $4$ bits, meaning we can represent values between 0 and $2^4-1=15$.\n",
        "\n",
        " * To produce the quantized representation, we need to be able to map the matrix values to and from this range.\n",
        " * For reasons that become important later, we will perform this mapping independently for each matrix row.\n",
        " * We will parametrize the mapping like this: $out = \\frac{in}{scale} + zero$, where $scale$ and $zero$ are row-wise constants.\n",
        " * For a matrix of size `(m, k)` ($m$ rows, $k$ columns) we will aggregate those parameters into two vectors `scale` and `zero` of size `(m, 1)`.\n",
        "\n",
        "**Task (0.5pt):** Complete the function below to perform this mapping:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "z1xDv2d12hw9"
      },
      "outputs": [],
      "source": [
        "def get_scale_and_zero(x: Tensor, max_abs: float) -> tuple[Tensor, Tensor]:\n",
        "    \"\"\" Given a tensor x of shape (m, k) and max_abs > 0 produce tensors scale and zero of shape (m, 1)\n",
        "        such that 0 < x / scale + zero < max_abs\"\"\"\n",
        "    # YOUR CODE HERE>>>>>>>>>\n",
        "    xmin = x.min(dim=1, keepdim=True)[0]\n",
        "    xmax = x.max(dim=1, keepdim=True)[0]\n",
        "\n",
        "    range_vals = xmax - xmin\n",
        "    scale = range_vals / max_abs\n",
        "    zero = torch.round(-xmin / scale)\n",
        "    # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "    return scale, zero\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "aZ8TZiGyi62M",
        "outputId": "317a967f-36b6-4bb6-8e68-820bf445f4a9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-671677848.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m15\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1023.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Scale can't be that large. The resulting interval is too wide\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m15\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1022.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Scale shouldn't be that small. The resulting interval is too narrow\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.001\u001b[0m \u001b[0;34m<\u001b[0m  \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mzero\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m15\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Testing your code\n",
        "\n",
        "x = torch.arange(512 * 1024).reshape(512, 1024).float()\n",
        "scale, zero = get_scale_and_zero(x, 15)\n",
        "assert scale.shape == (512, 1), \"scale is wrong shape\"\n",
        "assert zero.shape == (512, 1), \"zero is wrong shape\"\n",
        "assert torch.all(scale * 15 <= 1023.1), \"Scale can't be that large. The resulting interval is too wide\"\n",
        "assert torch.all(scale * 15 >= 1022.9), \"Scale shouldn't be that small. The resulting interval is too narrow\"\n",
        "assert torch.all(-0.001 <  x / scale + zero) and torch.all(x / scale + zero < 15 + 0.001)\n",
        "\n",
        "x = torch.zeros(128, 128)\n",
        "scale, zero = get_scale_and_zero(x, 15)\n",
        "assert torch.all(scale == 1) and torch.all(scale * 15 >= 0.99), \"If all the values in a row are identical, let us set scale to 1\"\n",
        "print(\"All tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E1DfQaSi62N"
      },
      "source": [
        "**Quantization**\n",
        "\n",
        "Having mapped the values into the allowed range, we can simply round them to obtain the quantized matrix. Complete the functions below to perform row-wise quantization. Note that:\n",
        " * You should `torch.clamp(...)` the quantized values to ensure that they are in the allowed range.\n",
        " * Some functions return the quantized matrix, as well as the quantization constants, because we'll need them to dequantize the matrix. Use `get_scale_and_zero` to obtain the them.\n",
        " * Note that we cast the quantized tensor to `uint8`, but the values themselves must be in the possibly narrower range, as determined by the number of bits. Obviously, we require the latter to be less or equal than 8.\n",
        "\n",
        "**Task (0.5pt):** Complete the function below to perform quantization:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZR0OZ0ai62N"
      },
      "outputs": [],
      "source": [
        "def quantize(x: Tensor, scale: Tensor, zero: Tensor, bits: int) -> Tensor:\n",
        "    \"\"\"Quantizes a tensor\n",
        "    Args:\n",
        "        x (Tensor): tensor to quantize\n",
        "        scale (Tensor): values interval mapping scale\n",
        "        zero (Tensor): values interval mapping zero\n",
        "        bits (int): number of bits to quantize to\n",
        "\n",
        "    Returns:\n",
        "        Tensor: quantized tensor in uint8\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE>>>>>>>>>\n",
        "    quantized_x = x / scale + zero\n",
        "    max_val = 2 ** bits - 1\n",
        "    quantized_x = torch.clamp(quantized_x, 0, max_val)\n",
        "\n",
        "    quantized_x = torch.round(quantized_x)\n",
        "    # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "    return quantized_x.to(torch.uint8)\n",
        "\n",
        "\n",
        "def dequantize(quantized_x: Tensor, scale: Tensor, zero: Tensor) -> Tensor:\n",
        "    \"\"\"Dequantize a tensor\n",
        "    Args:\n",
        "        quantized_x (Tensor): quantized tensor in uint8\n",
        "        scale (Tensor): values interval mapping scale\n",
        "        zero (Tensor): values interval mapping zero\n",
        "\n",
        "    Returns:\n",
        "        Tensor: dequantized tensor\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE>>>>>>>>>\n",
        "\n",
        "    quantized_x_float = quantized_x.float()\n",
        "    dequantized_x = (quantized_x_float - zero) * scale\n",
        "    return dequantized_x\n",
        "    # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "\n",
        "def measure_and_quantize(x: Tensor, bits: float) -> tuple[Tensor, Tensor, Tensor]:\n",
        "    \"\"\"Determine the values interval mapping parameters and quantize a tensor\n",
        "    Args:\n",
        "        x (Tensor): tensor to quantize\n",
        "        bits (float): number of bits to quantize to\n",
        "\n",
        "    Returns:\n",
        "        tuple[Tensor, Tensor, Tensor]: quantized tensor, scale, zero\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE>>>>>>>>>\n",
        "    max_abs = 2 ** bits - 1\n",
        "    scale, zero = get_scale_and_zero(x, max_abs)\n",
        "    x_quantized = quantize(x, scale, zero, int(bits))\n",
        "    # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "    return x_quantized, scale, zero\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WM8eIsR8i62O"
      },
      "outputs": [],
      "source": [
        "# Testing your code\n",
        "\n",
        "x = torch.arange(512 * 1024).reshape(512, 1024).float()\n",
        "scale, zero = get_scale_and_zero(x, 15)\n",
        "quantized_x, scale, zero = measure_and_quantize(x, 4)\n",
        "\n",
        "assert quantized_x.shape == x.shape, \"Shape of quantized_x is incorrect\"\n",
        "assert scale.shape == (512, 1), \"Shape of scale is incorrect\"\n",
        "assert zero.shape == (512, 1), \"Shape of zero is incorrect\"\n",
        "assert torch.all(quantized_x >= 0) and torch.all(quantized_x <= 15) and torch.any(quantized_x == 15), \"wrong quantized_x values range\"\n",
        "assert torch.allclose(x, dequantize(quantized_x, scale, zero), atol=50), \"Dequantized values are too far from the original values\"\n",
        "print(\"All tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBDvbhJSi62O"
      },
      "source": [
        "**Using the quantized matrix**\n",
        "\n",
        "To actually use the matrix, we'll have to map it's values back into their original form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMzGxzt-i62P"
      },
      "outputs": [],
      "source": [
        "class QuantizedLinear(nn.Module):\n",
        "    def __init__(self, quantized_weight, scale, zero, bias):\n",
        "        super().__init__()\n",
        "        self.quantized_weight = nn.Parameter(quantized_weight, requires_grad=False)\n",
        "        self.scale = nn.Parameter(scale, requires_grad=False)\n",
        "        self.zero = nn.Parameter(zero, requires_grad=False)\n",
        "        self.bias = nn.Parameter(bias.data.clone().detach()) if bias is not None else None\n",
        "\n",
        "    def forward(self, input):\n",
        "        return F.linear(input, dequantize(self.quantized_weight, self.scale, self.zero), self.bias)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncM_JzOii62P"
      },
      "source": [
        "This class will be used as a replacement for `nn.Linear`. It holds the quantized weight and only dequantizes it during it's forward passes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPaMiUC91VYH"
      },
      "source": [
        "# LLM Quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agCFfP7x2Au6"
      },
      "source": [
        "### RTN Quantization for LLaMA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwS6bTIwi62V"
      },
      "source": [
        "**Auxiliary functions:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vo0UYKvi62V"
      },
      "outputs": [],
      "source": [
        "def find_linear_layers(module: nn.Module, name='') -> dict[str, nn.Module]:\n",
        "    \"\"\"\n",
        "    Returns a dict of all nn.Linear submodules in a module with paths as keys\n",
        "    \"\"\"\n",
        "    if type(module) == nn.Linear:\n",
        "        return {name: module}\n",
        "    res = {}\n",
        "    for name1, child in module.named_children():\n",
        "        res.update(find_linear_layers(\n",
        "            child, name=name + '.' + name1 if name != '' else name1\n",
        "        ))\n",
        "    return res\n",
        "\n",
        "\n",
        "def replace_submodule(module, submodule_path, new_submodule):\n",
        "    \"\"\"\n",
        "    Replaces a submodule specified by a path with a new submodule\n",
        "    \"\"\"\n",
        "    submodule_names = submodule_path.split(\".\")\n",
        "    for submodule in submodule_names[:-1]:\n",
        "        module = getattr(module, submodule)\n",
        "    setattr(module, submodule_names[-1], new_submodule)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJALPHCSi62W"
      },
      "source": [
        "**Load-Quantize cycle**\n",
        "\n",
        "First, take a look at the function below. It uses the functions above to load the layers one by one and iterate over their `Linear` submodules replacing them with `QuantizedLinear`. A few things to keep in mind:\n",
        " * Note that the quantization happens on `.cuda()`, because we'll load *LLaMA* in `float16` which is not supported on `cpu`.\n",
        " * We call `torch.cuda.empty_cache()` after processing each layer because we'll have just enough *VRAM* for this to work.\n",
        " * The loaded model is placed in RAM.\n",
        "\n",
        "**Task (1.0pt):** implement RTN quantization for *LLaMA*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TRwggs3Lb2F"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def llama_rtn(model: LlamaForCausalLM, bits: int):\n",
        "    \"\"\"Iterates LLaMA layers one by one and quantizes them with RTN\n",
        "    Args:\n",
        "        model (LlamaForCausalLM): model to quabtuze\n",
        "        bits (int): number of bits to quantize to\n",
        "    \"\"\"\n",
        "    # Load and quantize all the layers\n",
        "    layers = model.model.layers\n",
        "    for i in trange(len(layers)):\n",
        "        # Move layer to \"cuda\" and replace all linear submodules with QuantizedLinear\n",
        "        # Use:\n",
        "        #   - find_linear_layers\n",
        "        #   - replace_submodule\n",
        "\n",
        "        layer = layers[i].cuda()\n",
        "        # YOUR CODE HERE>>>>>>>>>\n",
        "        for linear_path, linear_module in linear_layers.items():\n",
        "            weight = linear_module.weight.data\n",
        "            bias = linear_module.bias\n",
        "\n",
        "            quantized_weight, scale, zero = measure_and_quantize(weight, bits)\n",
        "\n",
        "            quantized_linear = QuantizedLinear(quantized_weight, scale, zero, bias)\n",
        "\n",
        "            replace_submodule(layer, linear_path, quantized_linear)\n",
        "        # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "        layers[i] = layer.cpu()\n",
        "        torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4OlcGF2aEts"
      },
      "source": [
        "### Testing the Quantized Model\n",
        "\n",
        "Now we have everything we need to quantize the _LLaMA-7B_ model to 4 bits. Let us do that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luUgnOhxaFcw"
      },
      "outputs": [],
      "source": [
        "SEED = 0\n",
        "BITS = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUD4z4t7a7z8"
      },
      "outputs": [],
      "source": [
        "model, tokenizer = get_llama_model_and_tokenizer()\n",
        "llama_rtn(model, BITS)\n",
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_names = [name for name, module in model.named_modules() if isinstance(module, torch.nn.Linear)]\n",
        "assert linear_names == ['lm_head'], f\"Only lm_head shall not be quantized, got {linear_names}\""
      ],
      "metadata": {
        "id": "unG_6fkOTEWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EN9tVawbUfG"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"What is the capital of France?\",\n",
        "    \"Can you explain the Pythagorean theorem?\",\n",
        "    \"What is photosynthesis?\",\n",
        "    \"Give me a summary of 'Romeo and Juliet'\",\n",
        "    \"How far is the moon from the Earth?\",\n",
        "    \"What is a haiku?\",\n",
        "]\n",
        "answers = []\n",
        "\n",
        "for question in tqdm(questions):\n",
        "    tokenized_input = tokenizer(\n",
        "        f\"QUESTION: {question}\\n ANSWER:\",\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            tokenized_input[\"input_ids\"].cuda(),\n",
        "            max_length=50, num_beams=3, early_stopping=True,\n",
        "        )[0]\n",
        "    answer = tokenizer.decode(output, skip_special_tokens=True)\n",
        "    answers.append(answer[:answer.find(\".\")] + \".\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-QFd87GjNvd"
      },
      "outputs": [],
      "source": [
        "print(*answers, sep=\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn-Vko3urrM0"
      },
      "outputs": [],
      "source": [
        "model = model.cpu()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOFpjGxX2H-J"
      },
      "source": [
        "### Evaluating the model\n",
        "\n",
        "Before we start quantizing the model itself, let us create a way to evaluate it's performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G6Muc5ZyupZ"
      },
      "source": [
        "**Downloading the data**\n",
        "\n",
        "As a metric of the models' performance, we'll use it's PPL on the [wikitext2](https://paperswithcode.com/dataset/wikitext-2) dataset. Let us download and tokenize it. We'll need two subsets of it:\n",
        " * Test set of size ... to evaluate the models.\n",
        " * A train subset of size ... that we'll use later for GPTQ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUSNnguPysaD"
      },
      "outputs": [],
      "source": [
        "SEED = 0\n",
        "train_batch, test_input_ids = get_wikitext2(SEED, 2048)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A77M_WBTuOLh"
      },
      "source": [
        "**Model offloading**\n",
        "\n",
        "We want to evaluate the model's performance on a large dataset. The model barely fits on the *GPU*, and we'll have to infer in on long text sequences. We don't have enought *VRAM* to do that.\n",
        "\n",
        "Instead, we'll keep most of the model in *RAM*, only transferring the layers to *GPU* as we go through them one by one, and putting them back when we're done.\n",
        "\n",
        "**Obtaining the first layer inputs**\n",
        "\n",
        "To start iterating over the layers, we'll first have to obtain the fist layer inputs. We use the function below to do it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbxZfwj8ipPF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, Tensor\n",
        "\n",
        "\n",
        "class Catcher(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # We know that LLaMA layers take a Tensor of hidden states,\n",
        "        # and some kwargs of which `position_embeddings` is required.\n",
        "        # `position_embeddings` are also the same for the entire dataset,\n",
        "        # so we only have to register the last ones\n",
        "        self.hidden_states = []\n",
        "        self.position_embeddings = None\n",
        "\n",
        "\n",
        "    def forward(self, hidden_states, **kwargs):\n",
        "        assert hidden_states.shape[0] == 1 # only one element from dataset\n",
        "        self.hidden_states.append(hidden_states[0])\n",
        "        self.position_embeddings = kwargs['position_embeddings']\n",
        "        raise ValueError\n",
        "\n",
        "    def get_the_catch(self):\n",
        "        return torch.stack(self.hidden_states), self.position_embeddings\n",
        "\n",
        "\n",
        "def get_first_layer_inputs(model: nn.Module, model_inputs: Tensor):\n",
        "    catcher = Catcher()\n",
        "    original_layers = model.model.layers\n",
        "\n",
        "    model.model.layers = nn.ModuleList((catcher,))\n",
        "    for sample in model_inputs:\n",
        "        try:\n",
        "            model(sample.unsqueeze(0))\n",
        "        except ValueError:\n",
        "            pass\n",
        "    model.model.layers = original_layers\n",
        "\n",
        "    return catcher.get_the_catch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFI_nTCXi62Y"
      },
      "source": [
        "**Forward passing layer-by-layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzEPMSsEi62Y"
      },
      "outputs": [],
      "source": [
        "def forward_pass_layer(layer: nn.Module, inps: torch.Tensor, outs: torch.Tensor, position_embeddings: Tensor):\n",
        "    \"\"\"Forward pass inps through the layer ONE INP AT A TIME saving the outputs into the corresponding elements of outs\"\"\"\n",
        "    for j in range(inps.shape[0]):\n",
        "        outs[j] = layer(inps[j].unsqueeze(0), position_embeddings=position_embeddings)[0]\n",
        "\n",
        "\n",
        "def get_batch_nll(model: nn.Module, batch: Tensor):\n",
        "    # Collect the first layer inputs, put them on .cuda()\n",
        "    inps, position_embeddings = get_first_layer_inputs(model, batch)\n",
        "    inps = inps.cuda()\n",
        "    position_embeddings = (position_embeddings[0].cuda(), position_embeddings[1].cuda())\n",
        "\n",
        "    # Create a buffer for layer outputs\n",
        "    outs = torch.zeros_like(inps)\n",
        "\n",
        "    # Forward pass through the layers\n",
        "    layers = model.model.layers\n",
        "    for i in trange(len(layers), leave=False):\n",
        "        layer = layers[i].cuda() # Take a layer and put in on .cuda()\n",
        "\n",
        "        forward_pass_layer(layer, inps, outs, position_embeddings) # Forward pass a layer\n",
        "        inps, outs = outs, inps # Prepare the inputs and the output buffer for the next layer. Reuse the existing buffers\n",
        "\n",
        "        layers[i] = layer.cpu() # Put layer back on .cpu()\n",
        "        del layer\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    # Calculate NLL\n",
        "    nll = 0\n",
        "    model.model.norm = model.model.norm.cuda()\n",
        "    model.lm_head = model.lm_head.cuda()\n",
        "    for i in range(inps.shape[0]):\n",
        "        lm_logits = model.lm_head(model.model.norm(inps[i].unsqueeze(0)))\n",
        "        labels = batch[i]\n",
        "        # Calculate the language modeling Negative Log Likelyhood\n",
        "        shift_logits = lm_logits[:, :-1, :]\n",
        "        shift_labels = labels[1:]\n",
        "        loss = torch.nn.functional.cross_entropy(\n",
        "            shift_logits.view(-1, shift_logits.size(-1)),\n",
        "            shift_labels.view(-1).cuda(),\n",
        "            reduction=\"sum\",\n",
        "        )\n",
        "        nll += float(loss)\n",
        "    model.model.norm = model.model.norm.cpu()\n",
        "    model.lm_head = model.lm_head.cpu()\n",
        "    return nll\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def llama_eval(model, test_input_ids):\n",
        "    print('Evaluating ...')\n",
        "\n",
        "    total_nll = 0\n",
        "    for batch in tqdm(torch.tensor_split(test_input_ids, 4)):\n",
        "        total_nll += get_batch_nll(model, batch)\n",
        "\n",
        "    # Calculate PPL\n",
        "    ppl = math.exp(total_nll / test_input_ids.numel())\n",
        "    print(f\"PPL: {ppl}\")\n",
        "    return ppl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHq3Z8RlLpuc"
      },
      "source": [
        "**Calculating PPL**\n",
        "\n",
        "We've already loaded and quantized the model. All that's left is to evaluate it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybS4iAjsq67Z"
      },
      "outputs": [],
      "source": [
        "rtn_ppl = llama_eval(model, test_input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "722oBDnwq_1x"
      },
      "outputs": [],
      "source": [
        "# Testing your code\n",
        "\n",
        "assert rtn_ppl > 18 and rtn_ppl < 20\n",
        "print(\"All tests passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urb_7OhSq_zA"
      },
      "outputs": [],
      "source": [
        "del model\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CQIk33arN6A"
      },
      "source": [
        "### GPTQ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t16SaWf3rQt7"
      },
      "source": [
        "GPTQ is the State Of The Art quantization algorithm for post-training DL model quantization. It works by sequentially quantizing the model's linear layer weights.\n",
        "\n",
        "Although in outputs results similar to what one would get with Round To Nearest quantization, it makes a key observations to boost it's end performance:\n",
        " * It is layer input aware (also referred to as \"1-Shot\" method), meaning int optimizes the quantized matrix to show best performance on inputs typically encountered in that layer.\n",
        "More formally, the problem can be formulated as:\n",
        "$$\n",
        "W_q = argmin_{\\widehat{W}}\\|XW^T - X\\widehat{W}^T\\|_2^2\n",
        "$$\n",
        ", where\n",
        " * $X$ is the input matrix of shape `(..., IN)`.\n",
        " * $XW^T$ is the unquantized output of shape `(..., OUT)`. We think of the norm above as taking a sum over those (...) dimensions.\n",
        " * $W$ is the unquantized weight of shape `(OUT, IN)`.\n",
        " * $\\widehat{W}$ is the quantized weight taken from some quantization grid.\n",
        "\n",
        "One can notice that the expression above is independent with regard to the rows of $W$ and $\\widehat{W}$, meaning we can solve it for each row in parallel. This is the reason why we're working with row-wise quantization in the first place. Notice that the quantization grid only depends on min/max values withing the row and not the quantization process, so we can think of it as fixed.\n",
        "\n",
        "and the dimension of the optimization problem is `IN`, which is too much to solve exactly. The algorithm proposes to solve it iteratively.\n",
        "\n",
        "Less us consider a vector of full precision weights $F$ and corresponding sent of inputs $X_F$. The corresponding objective is quadratic with Hessian\n",
        "$$\n",
        "H_F = 2X_F^TX_F^.\n",
        "$$\n",
        "The algorithm can be described like this:\n",
        " * Do the following steps until $F$ is fully quantized:\n",
        "    1. Given the next index to quantize $i$, and corresponding unquantized element $F_i$.\n",
        "    2. Quantize the coordinate by prjecting in onto the quantization grid $Q_i = quant(F_i)$.\n",
        "    3. Update all of the remaining weights $F_: = F_: - \\frac{F_i - quant(F_i)}{\\left[H_F^{-1}\\right]_{ii}}\\cdot\\left[H_F^{-1}\\right]_{i,:}$.\n",
        "    4. Exclude $i$ from $F$.\n",
        "\n",
        "It uses the inverse Hessian to slightly tune the remaining unquantized weights to mitigate the quantization error.\n",
        "\n",
        "As for how $i$ is chosen, an observation was made that iterating over indices in order of **decreasing diagonal Hessian elements** provides the best performance.\n",
        "\n",
        "There are a few more ideas that make this algorithm much faster:\n",
        " 1. We can represent the order of quantization (selection of $i$) by permuting the row in advance, and then iterating over the row element in order.\n",
        " $$\n",
        "   F_{i:} = F_{i:} - \\frac{F_{i} - quant(F_{i})}{\\left[H_F^{-1}\\right]_{ii}}\\cdot\\left[H_F^{-1}\\right]_{i,i:}\n",
        " $$\n",
        " 2. The problem is row-wise independent, meaning that we use the same permutation each row and perform those operations in a vector fashion for all the rows at the same time.\n",
        " $$\n",
        "   F_{:,i:} = F_{:,i:} - \\frac{F_{:,i} - quant(F_{:,i})}{\\left[H_F^{-1}\\right]_{ii}}\\odot\\left[H_F^{-1}\\right]_{i,i:}\\leftarrow\\text{\\textbf{ you'll have to code this}}\n",
        " $$\n",
        " 3. We don't actually need to recompute the inverse Hessian. At $i$-th step we only need its $t$-th row, and we can use fancy math to precompute the matrix containing all of those rows in advance.\n",
        " $$\n",
        "  H^{-1} = Cholesky(H^{-1})^T    \n",
        " $$\n",
        "\n",
        " 4. We don't need to tune all the remaining unquantized values right away. We can only apply the updates for the closest elements right away and accumulate all the other updates to apply them only once in a while.\n",
        "\n",
        "    We'll do this in block of fixed size, applying the updates inside of those blocks and updating the weights outside only when we're done with the block. To accumulate those updates, we'll collect the scaled quantization error\n",
        "    $$\n",
        "      Err_{:,i} =\\frac{F_{:,i} - quant(F_{:,i})}{\\left[H_F^{-1}\\right]_{ii}}\\text{ for all }i\\text{ in block}.\n",
        "    $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogTj9Op5raaD"
      },
      "source": [
        "**GPTQ within blocks**\n",
        "\n",
        "Implement GPTQ within the block. Iterate over the columns in ordered vector fashion, quantizing them one by one and updating all the remaining colums within the block.\n",
        "\n",
        "Return the quantized weight as well as the matrix of quantization errors that we'll need to tune the unquantized weights outside of the block.\n",
        "\n",
        "**Task (2.0pt):** Implement GPTQ block:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8GwQU5CrNv_"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def gptq_block(block_weight: Tensor, block_hessian_inverse: Tensor, scale: Tensor, zero: Tensor, bits: int) -> tuple[Tensor, Tensor]:\n",
        "    \"\"\"Perform GPTQ within block\n",
        "    Args:\n",
        "        block_weight (Tensor): weight to quantize of shape (OUT, BLOCK_SIZE)\n",
        "        block_hessian_inverse (Tensor): Cholesky inverse Hessian. Upper triangular of shape (BLOCK_SIZE, BLOCK_SIZE)\n",
        "        scale (Tensor): row-wise quantization constats of shape (OUT, 1)\n",
        "        zero (Tensor): row-wise quantization constats of shape (OUT, 1)\n",
        "        bits (int): number of bits to quantize() to\n",
        "\n",
        "    Returns:\n",
        "        tuple[Tensor, Tensor]: quantized weight and scaled quantization error\n",
        "    \"\"\"\n",
        "    block_weight = block_weight.clone()\n",
        "    quantized_block_weight = torch.zeros(block_weight.shape, dtype=torch.uint8, device=block_weight.device)\n",
        "    scaled_block_error = torch.zeros_like(block_weight)\n",
        "\n",
        "    # Interate over the block's columns\n",
        "    for i in range(block_weight.shape[1]):\n",
        "        # Get the column and the corresponding inverse Hessian\n",
        "        column_weight = block_weight[:, [i]]\n",
        "        hessian_slice = block_hessian_inverse[[i], i:]\n",
        "        # YOUR CODE HERE>>>>>>>>>\n",
        "        # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "    return quantized_block_weight, scaled_block_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgRy6B_didyY"
      },
      "outputs": [],
      "source": [
        "# Testing your code\n",
        "!wget -O gptq_block_weight_reference.pt https://raw.githubusercontent.com/yandexdataschool/nlp_course/2023/week10_efficiency/gptq_block_weight_reference.pt --no-check-certificate\n",
        "!wget -O gptq_block_error_reference.pt https://raw.githubusercontent.com/yandexdataschool/nlp_course/2023/week10_efficiency/gptq_block_error_reference.pt --no-check-certificate\n",
        "\n",
        "generator = torch.Generator()\n",
        "generator.manual_seed(0)\n",
        "\n",
        "weight = torch.rand((128, 128), generator=generator).cuda()\n",
        "scale, zero = get_scale_and_zero(weight, 15)\n",
        "\n",
        "block_weight = weight[:,:16]\n",
        "\n",
        "block_hessian_inverse = (torch.triu(torch.rand((16, 16), generator=generator), diagonal=1) + torch.diag(torch.rand(16, generator=generator) + 1)).cuda()\n",
        "quantized_block_weight, scaled_block_error = gptq_block(block_weight, block_hessian_inverse, scale, zero, 4)\n",
        "\n",
        "assert torch.all(quantized_block_weight == torch.load(\"gptq_block_weight_reference.pt\"))\n",
        "assert torch.allclose(scaled_block_error, torch.load(\"gptq_block_error_reference.pt\"), rtol=1e-5, atol=1e-06)\n",
        "\n",
        "print(\"All tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpXmzbg8y18R"
      },
      "source": [
        "**Now we can implement the full algorithm:**\n",
        " * Get row-wise quantization constants.\n",
        " * Sort the columns by decreasing Hessian diagonal values. Think about how you'd have to permute the Hessian as well.\n",
        " * Process the Hessian to obtain the precomputed inverse Hessian.\n",
        " * Iterate over the columns in blocks:\n",
        "    * Get the next block and quantize it.\n",
        "    * Tune all the following blocks to mitigate the quantization error.\n",
        "      $$\n",
        "         F_{:,block\\_end:} = F_{:,block\\_end:} - Err_{:,block\\_start:block\\_end}\\odot\\left[H_F^{-1}\\right]_{block\\_start:block\\_end,block\\_end:}\n",
        "      $$\n",
        " * Restore the original order for quantized columns.\n",
        "\n",
        "**Task (2.0pt):** implement the full algorithms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqI4FamprFPE"
      },
      "outputs": [],
      "source": [
        "def prepare_inverse_hessian(hessian: Tensor, percdamp: float) -> Tensor:\n",
        "    \"\"\"Precomputes inverse Hessian\n",
        "    Args:\n",
        "        hessian (Tensor): problem hessian\n",
        "        percdamp (float): diagonal damping constant for numerical stability\n",
        "    Returns:\n",
        "        Tensor: precomputed inverse Hessian\n",
        "    \"\"\"\n",
        "    damp = percdamp * torch.mean(torch.diag(hessian))\n",
        "    diag = torch.arange(hessian.shape[0], device=weight.device)\n",
        "    hessian[diag, diag] += damp\n",
        "    hessian = torch.linalg.cholesky(hessian)\n",
        "    hessian = torch.cholesky_inverse(hessian)\n",
        "    hessian = torch.linalg.cholesky(hessian, upper=True)\n",
        "    return hessian\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def gptq(weight: torch.Tensor, bits: int, hessian: torch.Tensor, blocksize:int=128, percdamp:float=.01) -> tuple[Tensor, Tensor, Tensor]:\n",
        "    \"\"\"Quantizes weight with GPTQ\n",
        "    Args:\n",
        "        weight (torch.Tensor): weight to quantize\n",
        "        bits (int): number of bits to quantize to\n",
        "        hessian (torch.Tensor): problem Hessian\n",
        "        blocksize (int, optional): Defaults to 128.\n",
        "        percdamp (float, optional): Hessian damping constant for numerical stability. Defaults to .01.\n",
        "\n",
        "    Returns:\n",
        "        tuple[Tensor, Tensor, Tensor]: quantized_weight, row-wise quantization scales, row-wise quantization zeroes\n",
        "    \"\"\"\n",
        "    dtype = weight.dtype\n",
        "    weight = weight.clone().detach()\n",
        "    weight = weight.float()\n",
        "    num_columns = weight.shape[1]\n",
        "    hessian = hessian.float()\n",
        "\n",
        "    # Identify and patch always-zero input coordinates\n",
        "    dead = torch.diag(hessian) == 0\n",
        "    hessian[dead, dead] = 1\n",
        "    weight[:, dead] = 0\n",
        "\n",
        "    # Get row-wise quantization constants\n",
        "    scale, zero = get_scale_and_zero(weight, 2 ** bits - 1)\n",
        "\n",
        "    # Sort the columns by decreasing Hessian diagonal values.\n",
        "    # Transform the hessian accordingly.\n",
        "    # YOUR CODE HERE>>>>>>>>>\n",
        "    perm = ...\n",
        "    invperm = ...\n",
        "\n",
        "    hessian = ...\n",
        "    weight = ...\n",
        "    # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "    # Process the Hessian to obtain the precomputed inverse Hessian\n",
        "    hessian_inverse = prepare_inverse_hessian(hessian, percdamp)\n",
        "\n",
        "    # Iterate over the columns in blocks\n",
        "    quantized_weight = torch.zeros(weight.shape, dtype=torch.uint8, device=weight.device)\n",
        "    for block_start in range(0, num_columns, blocksize):\n",
        "\n",
        "        block_end = min(block_start + blocksize, num_columns)\n",
        "\n",
        "        # Get the next block and quantize it\n",
        "        # YOUR CODE HERE>>>>>>>>>\n",
        "\n",
        "        # Tune all the following blocks to mitigate the quantization error\n",
        "        weight[:, block_end:] = ...\n",
        "        # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "    # Reverse the permutation of the quantized weight\n",
        "    # YOUR CODE HERE>>>>>>>>>\n",
        "    quantized_weight = ...\n",
        "    # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "    return quantized_weight, scale.to(dtype), zero.to(dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI1R_stdrFMk"
      },
      "outputs": [],
      "source": [
        "# Testing your code\n",
        "!wget -O gptq_weight_reference.pt https://raw.githubusercontent.com/yandexdataschool/nlp_course/2023/week10_efficiency/gptq_weight_reference.pt --no-check-certificate\n",
        "\n",
        "generator = torch.Generator()\n",
        "generator.manual_seed(0)\n",
        "\n",
        "hessian = torch.triu(torch.rand((128, 128), generator=generator) + 4 * torch.eye(128)).cuda().half()\n",
        "hessian += hessian.clone().T\n",
        "quantized_weight, _, _ = gptq(weight, 4, hessian, 32)\n",
        "\n",
        "assert torch.all(quantized_weight == torch.load(\"gptq_weight_reference.pt\"))\n",
        "\n",
        "print(\"All tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHAnRizBy8HC"
      },
      "source": [
        "**Sequential Model Quantization**\n",
        "\n",
        "The GPT quantization approach implemented here requires an ordered approach due to its input-dependent nature. For each `Linear` submodule within the GPT model, we need to ensure that the input data is representative of the actual operating conditions post-quantization. This involves propagating a batch of input samples through the model sequentially, with each layer's input being the output of the preceding **quantized** layers.\n",
        "\n",
        "The quantization process must follow a strict sequence both across and within layers. Within each layer, there is a predetermined order in which the submodules must be quantized, which is dictated by the dependencies between them. This order is defined by the \"sequential groups\".\n",
        "\n",
        "The steps of the algorithm are as follows:\n",
        "- Retrieve and prepare inputs for the first layer.\n",
        "- Iterate through each layer in the model:\n",
        "  - Load the current layer for processing.\n",
        "  - Within each layer, process the sequential groups of submodules:\n",
        "    - Attach forward hooks to collect input data to each submodule.\n",
        "    - Execute a forward pass through the layer to accumulate the necessary input data for quantization.\n",
        "    - Remove the hooks after data collection.\n",
        "    - Apply GPTQ to quantize the submodule weights using the accumulated input data.\n",
        "  - Perform another forward pass through the quantized layer to generate the inputs for the next layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMyrGkHqy-xg"
      },
      "outputs": [],
      "source": [
        "def get_accumulate_input_fn(name: str, hessians: Mapping[str, Tensor], num_samples: Mapping[str, int]):\n",
        "    \"\"\"Generate a callback that updates the corresponding hessians and counts when given input\n",
        "    Args:\n",
        "        name (str): module name\n",
        "        hessians (Mapping[str, Tensor]): a dict of modules' hessians, accessible by module name\n",
        "        num_samples (Mapping[str, int]): a dict of callback call counters\n",
        "    \"\"\"\n",
        "    def tmp(_, inp, out):\n",
        "        inp = inp[0].data # ... x hidden_size\n",
        "        inp = inp.reshape((-1, inp.shape[-1])) # inputs x hidden_size\n",
        "        inp = inp.t().float() # hidden_size x inputs\n",
        "        num_samples[name] += 1\n",
        "        if hessians[name] is None:\n",
        "            hessians[name] = inp.matmul(inp.t())\n",
        "        else:\n",
        "            hessians[name] += inp.matmul(inp.t())\n",
        "    return tmp\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def llama_gptq(model: LlamaForCausalLM, batch: Tensor, bits: int):\n",
        "    \"\"\"Iterates LLaMA layers one by one and quantizes them with GPTQ\n",
        "    Args:\n",
        "        model (LlamaForCausalLM): model to quantize\n",
        "        batch (Tensor): sample model inputs\n",
        "        bits (int): number of bits to quantize to\n",
        "    \"\"\"\n",
        "    # Collect the first layer inputs, put them on .cuda() (the same as in get_batch_nll)\n",
        "    inps, position_embeddings = get_first_layer_inputs(model, batch)\n",
        "    inps = inps.cuda()\n",
        "    position_embeddings = (position_embeddings[0].cuda(), position_embeddings[1].cuda())\n",
        "\n",
        "    # Create a buffer for layer outputs\n",
        "    outs = torch.zeros_like(inps)\n",
        "\n",
        "    # Forward pass through the layers\n",
        "    layers = model.model.layers\n",
        "    for i in trange(len(model.model.layers)):\n",
        "        layer = layers[i].cuda()\n",
        "        linear_layers = find_linear_layers(layer)\n",
        "\n",
        "        hessians = {name: None for name in linear_layers}\n",
        "        num_samples = {name: 0 for name in linear_layers}\n",
        "        handles = [\n",
        "            linear_layers[name].register_forward_hook(\n",
        "                get_accumulate_input_fn(name, hessians, num_samples)\n",
        "            ) for name in linear_layers\n",
        "        ]\n",
        "        forward_pass_layer(layer, inps, outs, position_embeddings)\n",
        "        for h in handles:\n",
        "            h.remove()\n",
        "\n",
        "        for name, linear in linear_layers.items():\n",
        "            q, scale, zero = gptq(linear.weight.data, bits, 2 * hessians[name] / num_samples[name])\n",
        "            quantized_linear = QuantizedLinear(q, scale, zero, linear.bias)\n",
        "            replace_submodule(layer, name, quantized_linear)\n",
        "\n",
        "        forward_pass_layer(layer, inps, outs, position_embeddings)\n",
        "        inps, outs = outs, inps\n",
        "        layers[i] = layer.cpu()\n",
        "        del layer\n",
        "        torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6lN_q-0zFej"
      },
      "source": [
        "**Evaluating the model with GPTQ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKRuiX7Vza96"
      },
      "outputs": [],
      "source": [
        "model, tokenizer = get_llama_model_and_tokenizer()\n",
        "llama_gptq(model, train_batch, BITS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53ARPLErza7N"
      },
      "outputs": [],
      "source": [
        "gptq_ppl = llama_eval(model, test_input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QwMLEqUza43"
      },
      "outputs": [],
      "source": [
        "# Testing your code\n",
        "\n",
        "assert gptq_ppl < 13\n",
        "print(\"All tests passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18BHd4Nnza2T"
      },
      "outputs": [],
      "source": [
        "del model\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E14awThL68JM"
      },
      "source": [
        "# Bonus: QUIK\n",
        "\n",
        "[QUIK](https://arxiv.org/abs/2310.09259) is an extension of GPTQ. It's main feature is that, in addition to model quantization, it also quantizes activations. That way, multiplication can be performed in `int`, leading to 2x-3x improvement in inference speed over GPTQ, which dequantizes the weights and performs multiplication in `float`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JipC2pi-idyg"
      },
      "source": [
        "### Different Range, Different Scales and Zeros\n",
        "\n",
        "At basic quantization level, QUIK already has a number of differences compared to GPTQ:\n",
        " 1. QUIK quantizes the weights to **signed** integer values for better stability of matrix multiplication.\n",
        " 2. QUIK enforces `zero` to be integer, to be able to perform `int` multiplication with it as well.\n",
        " 3. QUIK changes the sign of `zero` (compare `quik_dequantize` with `dequantize`) for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEtnoIS5R8Z8"
      },
      "outputs": [],
      "source": [
        "def quik_get_scale_and_zero(x: Tensor, max_abs: float) -> tuple[Tensor, Tensor]:\n",
        "    \"\"\" Given a tensor x of shape (m, k) and max_abs > 0 produce tensors scale and zero of shape (m, 1)\n",
        "        such that 0 < x / scale + zero < max_abs\"\"\"\n",
        "    if x.shape[-1] == 0:\n",
        "        return torch.ones(x.shape[:-1], dtype=x.dtype, device=x.device), torch.zeros(x.shape[:-1], dtype=torch.int, device=x.device)\n",
        "    xmin = x.min(-1)[0]\n",
        "    xmax = x.max(-1)[0]\n",
        "\n",
        "    scale = (xmax - xmin) / max_abs / 2\n",
        "    scale[scale == 0] = 1\n",
        "    zero = torch.round((xmax + xmin) / 2 / scale) # zero is int, since we want to use it in int operations\n",
        "\n",
        "    return scale.unsqueeze(-1), zero.unsqueeze(-1).to(torch.int)\n",
        "\n",
        "\n",
        "def quik_quantize(x: Tensor, scale: Tensor, zero: Tensor, bits: int) -> Tensor:\n",
        "    \"\"\"Given a tensor x quantize it, producing tensors quantized_x of torch.int8 dtype\n",
        "    Args:\n",
        "        x (Tensor): tensor to quantize\n",
        "        scale (Tensor): values interval mapping scale\n",
        "        zero (Tensor): values interval mapping zero\n",
        "        bits (int): number of bits to quantize to\n",
        "\n",
        "    Returns:\n",
        "        Tensor: quantized tensor in int8\n",
        "    \"\"\"\n",
        "    if x.shape[-1] == 0:\n",
        "        return torch.zeros(x.shape, dtype=torch.int8, device=x.device)\n",
        "    max_abs = 2 ** (bits - 1) - 1\n",
        "    quantized_x = torch.round(x / scale) - zero\n",
        "    quantized_x = torch.clamp(quantized_x, -max_abs, max_abs) # what are the allowed values for int8?\n",
        "    return quantized_x.to(torch.int8)\n",
        "\n",
        "\n",
        "def quik_dequantize(x: Tensor, scale: Tensor, zero: Tensor) -> Tensor:\n",
        "    \"\"\"Dequantize a tensor\n",
        "    Args:\n",
        "        quantized_x (Tensor): quantized tensor in int8\n",
        "        scale (Tensor): values interval mapping scale\n",
        "        zero (Tensor): values interval mapping zero\n",
        "\n",
        "    Returns:\n",
        "        Tensor: dequantized tensor\n",
        "    \"\"\"\n",
        "    return scale * x + scale * zero\n",
        "\n",
        "\n",
        "def quik_measure_and_quantize(x: Tensor, bits: float) -> tuple[Tensor, Tensor, Tensor]:\n",
        "    \"\"\"Determine the values interval mapping parameters and quantize a tensor\n",
        "    Args:\n",
        "        x (Tensor): tensor to quantize\n",
        "        bits (float): number of bits to quantize to\n",
        "\n",
        "    Returns:\n",
        "        tuple[Tensor, Tensor, Tensor]: quantized tensor, scale, zero\n",
        "    \"\"\"\n",
        "    max_abs = 2 ** (bits - 1) - 1\n",
        "    scale, zero = quik_get_scale_and_zero(x, max_abs)\n",
        "    x_quantized = quik_quantize(x, scale, zero, bits)\n",
        "    return x_quantized, scale, zero\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSqZunEhR-_Y"
      },
      "source": [
        "### Weight Quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-Vrjo7qidyj"
      },
      "source": [
        "**Full quantization**\n",
        "\n",
        "To determine the outliers, QUIK needs additional information about layer inputs. Namely, `l_inf_norms` - max module values for each input coordinate in a minibatch. We can see how it's used to extract outliers.\n",
        "\n",
        "The rest of the function, again, is copy-paste from `gptq(...)`. Feel free to reuse your code, but don't forget to replace `gptq_block` with `quik_block`.\n",
        "\n",
        "**Task:** Paste GPTQ code into QUIK:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def quik_block(block_weight: Tensor, block_hessian_inverse: Tensor, scale: Tensor, zero: Tensor, bits: int) -> tuple[Tensor, Tensor]:\n",
        "    \"\"\"NOTE: This function is allowed to alter the block_weight as we won't need those weights anymore\n",
        "\n",
        "    Args:\n",
        "        block_weight (Tensor): weight to quantize of shape (OUT, BLOCK_SIZE)\n",
        "        block_hessian_inverse (Tensor): Cholesky inverse Hessian. Upper triangular of shape (BLOCK_SIZE, BLOCK_SIZE)\n",
        "        scale (Tensor): row-wise quantization constants of shape (OUT, 1)\n",
        "        zero (Tensor): row-wise quantization constants of shape (OUT, 1)\n",
        "        bits (int): number of bits to quantize() to\n",
        "\n",
        "    Returns:\n",
        "        tuple[Tensor, Tensor]: quantized weight and scaled quantization error\n",
        "    \"\"\"\n",
        "    block_weight = block_weight.clone()\n",
        "    quantized_block_weight = torch.zeros(block_weight.shape, dtype=torch.int8, device=block_weight.device)\n",
        "    scaled_block_error = torch.zeros_like(block_weight)\n",
        "\n",
        "    # Iterate over the block's columns\n",
        "    for i in range(block_weight.shape[1]):\n",
        "        # Get the column and the corresponding inverse Hessian\n",
        "        column_weight = block_weight[:, [i]]\n",
        "        # YOUR CODE HERE>>>>>>>>>\n",
        "        # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "    return quantized_block_weight, scaled_block_error"
      ],
      "metadata": {
        "id": "gFHrPYcunO3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7TGlfLgidyj"
      },
      "outputs": [],
      "source": [
        "def quik(weight: torch.Tensor, bits: int, hessian: torch.Tensor, l_inf_norms: torch.Tensor, blocksize:int=128, percdamp:float=.01, n_outliers=128):\n",
        "    dtype = weight.dtype\n",
        "    weight = weight.clone().detach()\n",
        "    weight = weight.float()\n",
        "\n",
        "    # Identify and patch always-zero input coordinates\n",
        "    dead = torch.diag(hessian) == 0\n",
        "    hessian[dead, dead] = 1\n",
        "    weight[:, dead] = 0\n",
        "\n",
        "    # Identify outliers by decreasing l_inf_norms. Sort the remained by decrasing hessian values\n",
        "    perm = torch.argsort(l_inf_norms, descending=True)\n",
        "    perm[n_outliers:] = perm[n_outliers:][torch.argsort(torch.diag(hessian)[perm][n_outliers:], descending=True)]\n",
        "    # YOUR CODE HERE>>>>>>>>>\n",
        "    weight = ...\n",
        "    hessian = ...\n",
        "    # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "    # Process outliers\n",
        "    outlier_weight = weight[:,:n_outliers]\n",
        "    weight = weight[:,n_outliers:]\n",
        "    num_columns = weight.shape[1]\n",
        "    hessian = hessian[n_outliers:,:][:,n_outliers:]\n",
        "\n",
        "    max_abs = 2 ** (bits - 1) - 1\n",
        "    scale, zero = quik_get_scale_and_zero(weight, max_abs)\n",
        "\n",
        "    # Process the Hessian to obtain the precomputed inverse Hessian\n",
        "    damp = percdamp * torch.mean(torch.diag(hessian))\n",
        "    diag = torch.arange(num_columns, device=weight.device)\n",
        "    hessian[diag, diag] += damp\n",
        "    hessian = torch.linalg.cholesky(hessian)\n",
        "    hessian = torch.cholesky_inverse(hessian)\n",
        "    hessian = torch.linalg.cholesky(hessian, upper=True)\n",
        "    hessian_inverse = hessian\n",
        "\n",
        "    # Iterate over the columns in blocks\n",
        "    quantized_weight = torch.zeros(weight.shape, dtype=torch.int8, device=weight.device)\n",
        "    for block_start in range(0, num_columns, blocksize):\n",
        "        block_end = min(block_start + blocksize, num_columns)\n",
        "\n",
        "        # YOUR CODE HERE>>>>>>>>>\n",
        "        # Get the next block and quantize it\n",
        "        quantized_weight[:, block_start: block_end], ...\n",
        "        # Tune all the following blocks to mitigate the quantization error\n",
        "        weight[:, block_end: ] -= ...\n",
        "        # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "    return quantized_weight, scale.to(dtype), zero, outlier_weight.to(dtype), perm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GAoLdmOSF6-"
      },
      "source": [
        "### QUIK Linear Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RIy26cHidym"
      },
      "source": [
        "Reminder: `output = custom_kernel.int8_matmul(X, Y)` and `output = custom_kernel.int4_matmul(X, Y)` compute $XY^T$ (same as `nn.functional.linear`).\n",
        "\n",
        "Notice that `int8_matmul` takes the normal `torch.int8` tensors, but int4_matmul expects `int4` values densely packed into `torch.uint8` tensors. This is exactly what we wrote **Dense Integer Packing** for. They have a <font color='red'>severe limitation</font>: the dimension of multiplication must be divisible by 16.\n",
        "\n",
        "Now you have to implement the quantized forward pass:\n",
        "\n",
        " $$\n",
        " \\begin{align}\n",
        "    XW^T &= (Q_x \\cdot scale_x + zero_x \\cdot scale_x)(Q_w \\cdot scale_w + zero_w \\cdot scale_w)^T =\\\\\n",
        "    &= (Q_x  + zero_x)(Q_w + zero_w)^T \\cdot (scale_x \\odot scale_w^T) =\\\\\n",
        "    &= (Q_xQ_w^T + Q_x zero_w^T + zero_x Q_w^T + zero_x zero_w^T) \\cdot (scale_x \\odot scale_w^T)\n",
        " \\end{align}\n",
        " $$\n",
        "\n",
        "because of the kernel limitations mentioned above, only the largest integer multiplication ($Q_xQ_w^T$) can be done in `int`. Perform the other ones in `float`.\n",
        "\n",
        "**Task (3pt)**: implement QUIK forward pass and measure it's performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG8Y2aP4wDMK"
      },
      "outputs": [],
      "source": [
        "class QuikLinear(nn.Module):\n",
        "    def __init__(self, quantized_weight, weight_scale, weight_zero, outlier_weight, bias, bits: int, perm):\n",
        "        super().__init__()\n",
        "        self.bits = bits\n",
        "        self.perm = perm\n",
        "        self.n_outliers = outlier_weight.shape[1]\n",
        "\n",
        "        self.quantized_weight = nn.Parameter(quantized_weight, requires_grad=False)\n",
        "        self.weight_scale = nn.Parameter(weight_scale, requires_grad=False)\n",
        "        self.weight_zero = nn.Parameter(weight_zero, requires_grad=False)\n",
        "\n",
        "        self.outlier_weight = nn.Parameter(outlier_weight, requires_grad=False)\n",
        "        self.weights_reduced = self.quantized_weight.to(torch.int32).sum(dim=1).float()\n",
        "\n",
        "        if bias is not None:\n",
        "            self.bias = nn.Parameter(bias.data.clone().detach())\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        out_size, in_size = self.quantized_weight.shape\n",
        "        input = input[...,self.perm]\n",
        "        input_quantized, input_scale, input_zero = quik_measure_and_quantize(input[...,self.n_outliers:], self.bits)\n",
        "\n",
        "        outliers_result = F.linear(input[...,:self.n_outliers], self.outlier_weight, self.bias)\n",
        "        if input_quantized.shape[-1] == 0:\n",
        "            return outliers_result\n",
        "\n",
        "        # Convert necessary components to float\n",
        "        inputs_reduced = input_quantized.to(torch.int32).sum(dim=-1).float()\n",
        "        input_zero = input_zero.float()\n",
        "        weight_zero = self.weight_zero.data.float()\n",
        "\n",
        "        # Fully int operations\n",
        "        # YOUR CODE HERE>>>>>>>>>\n",
        "        quantized_result = ...\n",
        "        quantized_result = quantized_result.float()\n",
        "        # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "        # I wish those were int, but float operations\n",
        "        # YOUR CODE HERE>>>>>>>>>\n",
        "        quantized_result +=                   # inputs_reduced and weight_zero\n",
        "        quantized_result +=                   # input_zero and weights_reduced\n",
        "        quantized_result +=                   # input_zero and weight_zero\n",
        "        quantized_result = quantized_result * # something with scales\n",
        "        # <<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "        quantized_result = quantized_result.to(torch.float16)\n",
        "        results = quantized_result + outliers_result\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcT93zaCNA4r"
      },
      "source": [
        "### Loading the First LLaMA Layer Attention Q Projection and its Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CU8tqdd0z0h"
      },
      "outputs": [],
      "source": [
        "model, tokenizer = get_llama_model_and_tokenizer()\n",
        "inps, _ = get_first_layer_inputs(model, train_batch)\n",
        "inps = inps.cuda()\n",
        "layer = model.model.layers[0].self_attn.q_proj.cuda()\n",
        "del model\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n3SauNWNA4r"
      },
      "source": [
        "### Gathering the Layer Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hsx8WPe1Kek"
      },
      "outputs": [],
      "source": [
        "class AccumulatedInput:\n",
        "    hessians = None\n",
        "    num_samples = 0\n",
        "    actnorms = None\n",
        "\n",
        "@torch.no_grad()\n",
        "def accumulate_layer_input(_, inp, out):\n",
        "    inp = inp.reshape((-1, inp.shape[-1])) # inputs x hidden_size\n",
        "    inp = inp.t().float() # hidden_size x inputs\n",
        "    AccumulatedInput.num_samples += 1\n",
        "    if AccumulatedInput.hessians is None:\n",
        "        AccumulatedInput.hessians = inp.matmul(inp.t())\n",
        "        AccumulatedInput.actnorms = inp.abs().amax(dim=1)\n",
        "    else:\n",
        "        AccumulatedInput.hessians += inp.matmul(inp.t())\n",
        "        AccumulatedInput.actnorms = torch.maximum(AccumulatedInput.actnorms, inp.abs().amax(dim=1))\n",
        "\n",
        "\n",
        "for inp in inps:\n",
        "    accumulate_layer_input(None, inp, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frvUz5b51Of3"
      },
      "outputs": [],
      "source": [
        "OUT = layer.weight.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWC3HT2D1Pu0"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    reference = torch.stack(tuple(layer(inp).float() for inp in inps)).reshape(-1, OUT).mean(dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OeYCLNoNA4s"
      },
      "source": [
        "### Benchmarking MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI6ShN5gZby9"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    quantized_weight, scale, zero = measure_and_quantize(layer.weight.data, 8)\n",
        "    shit = QuantizedLinear(quantized_weight, scale, zero, layer.bias)\n",
        "\n",
        "    result = torch.stack(tuple(shit(inp).float() for inp in inps)).reshape(-1, OUT).mean(dim=0)\n",
        "\n",
        "    rtn_mse = float(torch.pow(result - reference, 2).mean() ** (1/2))\n",
        "    print(\"MSE:\", rtn_mse)\n",
        "\n",
        "assert rtn_mse < 8e-5 and rtn_mse > 7e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AifKxdLHZhii"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    quantized_weight, scale, zero = gptq(layer.weight.data, 8, 2 * AccumulatedInput.hessians / AccumulatedInput.num_samples)\n",
        "    shit = QuantizedLinear(quantized_weight, scale, zero, layer.bias)\n",
        "\n",
        "    result = torch.stack(tuple(shit(inp).float() for inp in inps)).reshape(-1, OUT).mean(dim=0)\n",
        "\n",
        "    gptq_mse = float(torch.pow(result - reference, 2).mean() ** (1/2))\n",
        "    print(\"MSE:\", gptq_mse)\n",
        "\n",
        "assert gptq_mse < 3e-5 and gptq_mse > 1.5e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBAhlxPcF0Mv"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "with torch.no_grad():\n",
        "    quantized_weight, scale, zero, outlier_weight, perm = quik(layer.weight.data, 8, 2 * AccumulatedInput.hessians / AccumulatedInput.num_samples, AccumulatedInput.actnorms, n_outliers=0)\n",
        "    shit = QuikLinear(quantized_weight, scale, zero, outlier_weight, layer.bias, 8, perm)\n",
        "\n",
        "    result = torch.stack(tuple(shit(inp).float() for inp in inps)).reshape(-1, OUT).mean(dim=0)\n",
        "\n",
        "    quik_0_mse = float(torch.pow(result - reference, 2).mean() ** (1/2))\n",
        "    print(\"MSE:\", quik_0_mse)\n",
        "\n",
        "assert quik_0_mse < 3.2e-5 and quik_0_mse > 2.8e-5, f\"{quik_0_mse}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euq4H-VwZj9Q"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "with torch.no_grad():\n",
        "    quantized_weight, scale, zero, outlier_weight, perm = quik(layer.weight.data, 8, 2 * AccumulatedInput.hessians / AccumulatedInput.num_samples, AccumulatedInput.actnorms, n_outliers=256)\n",
        "    shit = QuikLinear(quantized_weight, scale, zero, outlier_weight, layer.bias, 8, perm)\n",
        "\n",
        "    result = torch.stack(tuple(shit(inp).float() for inp in inps)).reshape(-1, OUT).mean(dim=0)\n",
        "\n",
        "    quik_256_mse = float(torch.pow(result - reference, 2).mean() ** (1/2))\n",
        "    print(\"MSE:\", quik_256_mse)\n",
        "\n",
        "assert quik_256_mse < 2.8e-5 and quik_256_mse > 2.5e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J0ychH4GDUk"
      },
      "outputs": [],
      "source": [
        "fruits = ['GPTQ', 'QUIK\\n256 outliers', 'QUIK\\n0 outliers', 'RNT']\n",
        "counts = [gptq_mse, quik_256_mse, quik_0_mse, rtn_mse]\n",
        "bar_labels = ['green', 'blue', 'blue', 'red']\n",
        "bar_colors = ['green', 'blue', 'blue', 'red']\n",
        "\n",
        "plt.bar(fruits, counts, label=bar_labels, color=bar_colors)\n",
        "plt.ylabel(\"Layer MSE\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF78dQBVIASz"
      },
      "source": [
        "As we can see, QUIK allows for errors smaller than RTN despite utilizing quantized activations, and addition of outliesr further decreases the error, bringing it closer to GPTQ. As we have seen in `benchmark.ipynb`, `int` matmul can lead to 2x-3x speedup over `float16`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFp2mztPGYY4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "JipC2pi-idyg"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "-1.-1.-1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c063897199da419aaabfd427c1c2dad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9dd5fb4871994810bc1090b7dc28ae9c",
              "IPY_MODEL_635b4af413e2400db1f5a3fea54de9ca",
              "IPY_MODEL_7bad5b4030fb40cc839ee31c04952bde"
            ],
            "layout": "IPY_MODEL_53435bc10af34cf6b157a5113e485811"
          }
        },
        "9dd5fb4871994810bc1090b7dc28ae9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ab3b751044843159bff1bf4f9deca5f",
            "placeholder": "​",
            "style": "IPY_MODEL_214af78205de4dc2a9254bd58689b3bb",
            "value": "Iterating BATCH_SIZE: 100%"
          }
        },
        "635b4af413e2400db1f5a3fea54de9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84376e467af44c678d6bd5d2501f25f4",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1d25633c7ad458f82e41c2ff80f22c0",
            "value": 10
          }
        },
        "7bad5b4030fb40cc839ee31c04952bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44670b0fc90c4d46a97e4e9e72690363",
            "placeholder": "​",
            "style": "IPY_MODEL_bf7023e475ac4d1e88b1952ba49af6a7",
            "value": " 10/10 [00:15&lt;00:00,  1.55s/it]"
          }
        },
        "53435bc10af34cf6b157a5113e485811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab3b751044843159bff1bf4f9deca5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "214af78205de4dc2a9254bd58689b3bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84376e467af44c678d6bd5d2501f25f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1d25633c7ad458f82e41c2ff80f22c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44670b0fc90c4d46a97e4e9e72690363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7023e475ac4d1e88b1952ba49af6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95cbb03a29ac445d888b96352d3be3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15bf3854c4cb4d95b77752a322750492",
              "IPY_MODEL_89385b373b924530ab7fbbc3746d2e11",
              "IPY_MODEL_9520be933e0c444d9f7057e391222f1f"
            ],
            "layout": "IPY_MODEL_19997800a9bf449b9161684d423c00c8"
          }
        },
        "15bf3854c4cb4d95b77752a322750492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17168fc1f8c244288bd17e5ab29f3f1b",
            "placeholder": "​",
            "style": "IPY_MODEL_19509b2ea4e947c3bc07501e3e76fe5a",
            "value": "config.json: 100%"
          }
        },
        "89385b373b924530ab7fbbc3746d2e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a5c54a1f4eb4376bc2968a98c6722b9",
            "max": 843,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc0d4a85c37d4c28af2f3d94dc374a98",
            "value": 843
          }
        },
        "9520be933e0c444d9f7057e391222f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba4c72f900554e7f96c70447f05ad759",
            "placeholder": "​",
            "style": "IPY_MODEL_5110b0dc0c7344e5b83b6f69034f445b",
            "value": " 843/843 [00:00&lt;00:00, 91.2kB/s]"
          }
        },
        "19997800a9bf449b9161684d423c00c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17168fc1f8c244288bd17e5ab29f3f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19509b2ea4e947c3bc07501e3e76fe5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a5c54a1f4eb4376bc2968a98c6722b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc0d4a85c37d4c28af2f3d94dc374a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba4c72f900554e7f96c70447f05ad759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5110b0dc0c7344e5b83b6f69034f445b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31fc111c34b74ae4ad65a86056652907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50f8a893ad0c43288f39f0edfdf32162",
              "IPY_MODEL_f10e8d3cbb1845e19f687978ad26f2c3",
              "IPY_MODEL_3726a6384d7449c7b0a3834c2a0c2424"
            ],
            "layout": "IPY_MODEL_f41b50bd4a764c2984978027c1afff6e"
          }
        },
        "50f8a893ad0c43288f39f0edfdf32162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49f4dcb85f5748a2a29193e70b65b661",
            "placeholder": "​",
            "style": "IPY_MODEL_84ca9d1501e843a79be8c93474b6130a",
            "value": "model.safetensors: 100%"
          }
        },
        "f10e8d3cbb1845e19f687978ad26f2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75c76f5d9ee746b699d73b7e20185854",
            "max": 2471645608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4e2dcd79eeb4947b9d7d1d079f8b752",
            "value": 2471645608
          }
        },
        "3726a6384d7449c7b0a3834c2a0c2424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be988790010f48a5a1ee73409772d101",
            "placeholder": "​",
            "style": "IPY_MODEL_a770f93162d74637be238192e77b5a18",
            "value": " 2.47G/2.47G [01:43&lt;00:00, 23.4MB/s]"
          }
        },
        "f41b50bd4a764c2984978027c1afff6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49f4dcb85f5748a2a29193e70b65b661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84ca9d1501e843a79be8c93474b6130a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75c76f5d9ee746b699d73b7e20185854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4e2dcd79eeb4947b9d7d1d079f8b752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be988790010f48a5a1ee73409772d101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a770f93162d74637be238192e77b5a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe91014155e64612863f7a1d2ffdaa23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_207c7bb9d7754d068019ca3d9015f1a5",
              "IPY_MODEL_a869f6f9a3344fa2a85202c6288eaf0d",
              "IPY_MODEL_a3c6933c353b443d826e0399f59e273c"
            ],
            "layout": "IPY_MODEL_2058b7f1b30a4551a49461d6b6a6b033"
          }
        },
        "207c7bb9d7754d068019ca3d9015f1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_852ed38469864b24a544506f4ac04111",
            "placeholder": "​",
            "style": "IPY_MODEL_427209bdd0224f38922702d7c6d470fd",
            "value": "generation_config.json: 100%"
          }
        },
        "a869f6f9a3344fa2a85202c6288eaf0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a638393987c4894acdc346d2c1ae04c",
            "max": 186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c85d05e373e4fb797ebc4dd46253edc",
            "value": 186
          }
        },
        "a3c6933c353b443d826e0399f59e273c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f42719e8383243ba9c9648eb31b3930b",
            "placeholder": "​",
            "style": "IPY_MODEL_7888f1e3a61d460fa74f0ddcf957e9ee",
            "value": " 186/186 [00:00&lt;00:00, 20.3kB/s]"
          }
        },
        "2058b7f1b30a4551a49461d6b6a6b033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "852ed38469864b24a544506f4ac04111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "427209bdd0224f38922702d7c6d470fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a638393987c4894acdc346d2c1ae04c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c85d05e373e4fb797ebc4dd46253edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f42719e8383243ba9c9648eb31b3930b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7888f1e3a61d460fa74f0ddcf957e9ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "479feacabcf441db943d8be57e805fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dac627239fe749019cf220f05beb19d7",
              "IPY_MODEL_f4fd1018467a4d7cae32b1a31bcaa302",
              "IPY_MODEL_5ae71255c7834ef08a16cb8eca8adefa"
            ],
            "layout": "IPY_MODEL_83355ce9d5b24be182aeeebb2771636a"
          }
        },
        "dac627239fe749019cf220f05beb19d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bba13416cb4042cbbdfc40cd31a22459",
            "placeholder": "​",
            "style": "IPY_MODEL_11db54bdbf884b1c9ef1b470200ba22e",
            "value": "tokenizer_config.json: "
          }
        },
        "f4fd1018467a4d7cae32b1a31bcaa302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c89ac7b561244b369248eb98093fb710",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52967c4fc74848c28f2b50acd242045b",
            "value": 1
          }
        },
        "5ae71255c7834ef08a16cb8eca8adefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55553a575ffb4434a033c76db8895e85",
            "placeholder": "​",
            "style": "IPY_MODEL_31da59e2aa4d425990fc9be032522409",
            "value": " 50.5k/? [00:00&lt;00:00, 5.13MB/s]"
          }
        },
        "83355ce9d5b24be182aeeebb2771636a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bba13416cb4042cbbdfc40cd31a22459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11db54bdbf884b1c9ef1b470200ba22e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c89ac7b561244b369248eb98093fb710": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "52967c4fc74848c28f2b50acd242045b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55553a575ffb4434a033c76db8895e85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31da59e2aa4d425990fc9be032522409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65c734050521462a95a2136130323d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31bb6fdee1484ba3a1a79c9450722b4c",
              "IPY_MODEL_431c8c3fdb884d7ba231bda49ddae8c2",
              "IPY_MODEL_1d79e8641f7c43728316fb3ceb98927b"
            ],
            "layout": "IPY_MODEL_075a048ab4a9452a8e5ac27302e243cc"
          }
        },
        "31bb6fdee1484ba3a1a79c9450722b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fb1b2d01f234bae97e9b53cbc007c55",
            "placeholder": "​",
            "style": "IPY_MODEL_06be226b70f044c0b66c521d379d7d6c",
            "value": "tokenizer.json: "
          }
        },
        "431c8c3fdb884d7ba231bda49ddae8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f545db5976b34e689952054c628f6880",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_966a6bfdc93c4dba8c5aef2db95f205d",
            "value": 1
          }
        },
        "1d79e8641f7c43728316fb3ceb98927b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c67354be57f641e19d0b4f25a471c472",
            "placeholder": "​",
            "style": "IPY_MODEL_87fc35e089f548b1a993047b30fdb121",
            "value": " 9.09M/? [00:00&lt;00:00, 22.6MB/s]"
          }
        },
        "075a048ab4a9452a8e5ac27302e243cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb1b2d01f234bae97e9b53cbc007c55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06be226b70f044c0b66c521d379d7d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f545db5976b34e689952054c628f6880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "966a6bfdc93c4dba8c5aef2db95f205d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c67354be57f641e19d0b4f25a471c472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87fc35e089f548b1a993047b30fdb121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e57806acbf14d23aca16c1559621258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1602613a80ae4822af657eaa4526ba1d",
              "IPY_MODEL_548f622055a646ef8fb4c9ba8cc29c9e",
              "IPY_MODEL_3857a29be8154b54ab568a808dd17cec"
            ],
            "layout": "IPY_MODEL_e5054d2bf38346ffa8797c7df05a92b7"
          }
        },
        "1602613a80ae4822af657eaa4526ba1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05633451b86647608b7e46d6db4a9dbc",
            "placeholder": "​",
            "style": "IPY_MODEL_8436554294994c218e30e9807636b4f8",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "548f622055a646ef8fb4c9ba8cc29c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f61b38bd1a42468a13aa57b7f17ab7",
            "max": 301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_daa811b3404c4b8084104ef4241a0057",
            "value": 301
          }
        },
        "3857a29be8154b54ab568a808dd17cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daed8d1eb3894beeabab2d2234a7295c",
            "placeholder": "​",
            "style": "IPY_MODEL_38a8e15d5907485cb843d056f83bdc46",
            "value": " 301/301 [00:00&lt;00:00, 37.1kB/s]"
          }
        },
        "e5054d2bf38346ffa8797c7df05a92b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05633451b86647608b7e46d6db4a9dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8436554294994c218e30e9807636b4f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78f61b38bd1a42468a13aa57b7f17ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daa811b3404c4b8084104ef4241a0057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "daed8d1eb3894beeabab2d2234a7295c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38a8e15d5907485cb843d056f83bdc46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c993d0bbaaba41fe8e601b5b1d178fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9204a05dca284862b9f56556b7d50ec3",
              "IPY_MODEL_6efcff50dcc74a1cbe5ff7532a7368ad",
              "IPY_MODEL_0bc7c0482b8a4cdf9f92cba70fcb4f5c"
            ],
            "layout": "IPY_MODEL_cc59e4c920564fb99ac0e41a0bcb89ed"
          }
        },
        "9204a05dca284862b9f56556b7d50ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d4bd0005a5d4ee3ac09878f199fbba2",
            "placeholder": "​",
            "style": "IPY_MODEL_7fa665f428f44157adbe8fe2892acb2b",
            "value": "README.md: "
          }
        },
        "6efcff50dcc74a1cbe5ff7532a7368ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5da01a3dea5b4bf69c4a401c6418376e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a223a03238949fd8b13e462ed1c75c2",
            "value": 1
          }
        },
        "0bc7c0482b8a4cdf9f92cba70fcb4f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a9c27c09cd94c4fa74ced6ad98f7a68",
            "placeholder": "​",
            "style": "IPY_MODEL_9327acabe1394fdbbfb5baceb36014b0",
            "value": " 10.5k/? [00:00&lt;00:00, 1.13MB/s]"
          }
        },
        "cc59e4c920564fb99ac0e41a0bcb89ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d4bd0005a5d4ee3ac09878f199fbba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fa665f428f44157adbe8fe2892acb2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5da01a3dea5b4bf69c4a401c6418376e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6a223a03238949fd8b13e462ed1c75c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a9c27c09cd94c4fa74ced6ad98f7a68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9327acabe1394fdbbfb5baceb36014b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c87b8cb45ed47f7b9889da6812e6621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c275fe230df84ba5835b0fff72ad52fa",
              "IPY_MODEL_6014f22307214db19aeb7220c15319f3",
              "IPY_MODEL_44b4f390a015471099877615341f268c"
            ],
            "layout": "IPY_MODEL_26b9afd36abd43a3bab37af1cf50174f"
          }
        },
        "c275fe230df84ba5835b0fff72ad52fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53f4be8f9c5f4a96bbf8df9087650363",
            "placeholder": "​",
            "style": "IPY_MODEL_6e4579ba75154502b01a63f12eeb126b",
            "value": "wikitext-2-raw-v1/test-00000-of-00001.pa(…): 100%"
          }
        },
        "6014f22307214db19aeb7220c15319f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad7e7e73fa594489bb2a91cc2cb904c4",
            "max": 732610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bf185d52d864e5787d3ce6ebc6d1994",
            "value": 732610
          }
        },
        "44b4f390a015471099877615341f268c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f64bb86c8e14bb2aa8e73e5512bd5ba",
            "placeholder": "​",
            "style": "IPY_MODEL_43c9861f3f4b401fbca3fbc4ca3903f8",
            "value": " 733k/733k [00:00&lt;00:00, 66.3kB/s]"
          }
        },
        "26b9afd36abd43a3bab37af1cf50174f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f4be8f9c5f4a96bbf8df9087650363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e4579ba75154502b01a63f12eeb126b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad7e7e73fa594489bb2a91cc2cb904c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bf185d52d864e5787d3ce6ebc6d1994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f64bb86c8e14bb2aa8e73e5512bd5ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43c9861f3f4b401fbca3fbc4ca3903f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdf0fa43de30409d839b890c37799e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11dcbf8e53c84b4b9e67ad0dc83c141e",
              "IPY_MODEL_354785540e8c4bee81344dee4e183b8a",
              "IPY_MODEL_6787773de99d4cc484329167140b95fb"
            ],
            "layout": "IPY_MODEL_59773df278a0432dbd26dcb0be519208"
          }
        },
        "11dcbf8e53c84b4b9e67ad0dc83c141e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9110795d478c4951a061f46178c52ae0",
            "placeholder": "​",
            "style": "IPY_MODEL_6e5b78e39de84b4f9dd8b7f28b3fb2d5",
            "value": "wikitext-2-raw-v1/train-00000-of-00001.p(…): 100%"
          }
        },
        "354785540e8c4bee81344dee4e183b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed8957d6f01e4853921832026c0c60d8",
            "max": 6357543,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87902293a18744a6bb09d21329c2a7a6",
            "value": 6357543
          }
        },
        "6787773de99d4cc484329167140b95fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45bf66463ee54ec3b75f4b638e58cd97",
            "placeholder": "​",
            "style": "IPY_MODEL_986f4fc7e48548ba86af0b9b07942f21",
            "value": " 6.36M/6.36M [00:00&lt;00:00, 538kB/s]"
          }
        },
        "59773df278a0432dbd26dcb0be519208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9110795d478c4951a061f46178c52ae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e5b78e39de84b4f9dd8b7f28b3fb2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed8957d6f01e4853921832026c0c60d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87902293a18744a6bb09d21329c2a7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45bf66463ee54ec3b75f4b638e58cd97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "986f4fc7e48548ba86af0b9b07942f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7655a8335c0e420f849acab758829244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d22582216834dc0b1e47130662bbd17",
              "IPY_MODEL_db67e2be7cc7430a9719d575311c25fe",
              "IPY_MODEL_87217e1ec47b4d0493de22d340b79971"
            ],
            "layout": "IPY_MODEL_66f46daf054446ff84b0ce15b1d4a3fe"
          }
        },
        "2d22582216834dc0b1e47130662bbd17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cf35ab59b59473badfa2f01e3c295f0",
            "placeholder": "​",
            "style": "IPY_MODEL_0cf5618a902646839ccb497932862c65",
            "value": "wikitext-2-raw-v1/validation-00000-of-00(…): 100%"
          }
        },
        "db67e2be7cc7430a9719d575311c25fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d64e42358784333b0e0234f00be3c08",
            "max": 657209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bd182c79c844405b9bb641af408e21a",
            "value": 657209
          }
        },
        "87217e1ec47b4d0493de22d340b79971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_506be2f2bcfd4eaabe5aee72afd840af",
            "placeholder": "​",
            "style": "IPY_MODEL_71173630c8304831bf5e21a6cafaa1fa",
            "value": " 657k/657k [00:00&lt;00:00, 99.2kB/s]"
          }
        },
        "66f46daf054446ff84b0ce15b1d4a3fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cf35ab59b59473badfa2f01e3c295f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf5618a902646839ccb497932862c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d64e42358784333b0e0234f00be3c08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bd182c79c844405b9bb641af408e21a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "506be2f2bcfd4eaabe5aee72afd840af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71173630c8304831bf5e21a6cafaa1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c41d071a80249ac8e5c3a1b2d6a76c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d150ff9a0c644bfa888e4d56082232fd",
              "IPY_MODEL_4073dbfa26044cb29269164441731b28",
              "IPY_MODEL_ad9085d03275431b96c4ccf17535a7fb"
            ],
            "layout": "IPY_MODEL_2331db39933f4e2482aed65c821c3fcc"
          }
        },
        "d150ff9a0c644bfa888e4d56082232fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b65466a57ad041e182cbc5060a75e8e1",
            "placeholder": "​",
            "style": "IPY_MODEL_ef48b2c19d0b4a0eae11da3cb8f14df2",
            "value": "Generating test split: 100%"
          }
        },
        "4073dbfa26044cb29269164441731b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_314e58f4b4bd4d189ff265bf6bf26173",
            "max": 4358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce0c8c60b7fa498e8426774b61f1cdd5",
            "value": 4358
          }
        },
        "ad9085d03275431b96c4ccf17535a7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cc7bf93b7294be49cd9dbce4305cb29",
            "placeholder": "​",
            "style": "IPY_MODEL_9f6e562d526041f1b9127cfb2a7e6d79",
            "value": " 4358/4358 [00:00&lt;00:00, 7559.89 examples/s]"
          }
        },
        "2331db39933f4e2482aed65c821c3fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b65466a57ad041e182cbc5060a75e8e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef48b2c19d0b4a0eae11da3cb8f14df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "314e58f4b4bd4d189ff265bf6bf26173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0c8c60b7fa498e8426774b61f1cdd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cc7bf93b7294be49cd9dbce4305cb29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f6e562d526041f1b9127cfb2a7e6d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3109995be6f945d88619cb69fc071ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd753f0774b246bdbba9fbe3fe67bc10",
              "IPY_MODEL_03d0b0efa3244d988cd8ecec9ca536d2",
              "IPY_MODEL_124a1b9ea21f4f72a09657bcf68c839e"
            ],
            "layout": "IPY_MODEL_02b08e9f4d6042829b0628b032ee1a09"
          }
        },
        "fd753f0774b246bdbba9fbe3fe67bc10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36dbee7bc4a1462682ebe6ee0cdf6110",
            "placeholder": "​",
            "style": "IPY_MODEL_189853cf6aba410d833cd99f2b2c6771",
            "value": "Generating train split: 100%"
          }
        },
        "03d0b0efa3244d988cd8ecec9ca536d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c4c7d7393443b9b885896b1eb4f931",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c578567f5bc4c3eb0fdce60ce0aeceb",
            "value": 36718
          }
        },
        "124a1b9ea21f4f72a09657bcf68c839e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0f9648951304be78e6c30b61ed9baf4",
            "placeholder": "​",
            "style": "IPY_MODEL_e2626d6abe8b4d4ea23fc56643ae79bc",
            "value": " 36718/36718 [00:00&lt;00:00, 466054.93 examples/s]"
          }
        },
        "02b08e9f4d6042829b0628b032ee1a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36dbee7bc4a1462682ebe6ee0cdf6110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "189853cf6aba410d833cd99f2b2c6771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66c4c7d7393443b9b885896b1eb4f931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c578567f5bc4c3eb0fdce60ce0aeceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0f9648951304be78e6c30b61ed9baf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2626d6abe8b4d4ea23fc56643ae79bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9582dd2e791a4e0a8a77ae0a0f7b3489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1446e858c82e4d529661191d9e22701f",
              "IPY_MODEL_dee404200b7e448da49d7ecb992ca44a",
              "IPY_MODEL_1ca2a3ec43b3450d845b5ba2043e311e"
            ],
            "layout": "IPY_MODEL_8b39389aded949ad8eb393aa4543cf23"
          }
        },
        "1446e858c82e4d529661191d9e22701f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88b9fc2a34aa426d95b095c0939ebc42",
            "placeholder": "​",
            "style": "IPY_MODEL_8686ac8daa3b44b8ad562f37f32289df",
            "value": "Generating validation split: 100%"
          }
        },
        "dee404200b7e448da49d7ecb992ca44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0726f1576eb44d7b4f623d82e239856",
            "max": 3760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89cc6d30d6e0416e8997b57042499df9",
            "value": 3760
          }
        },
        "1ca2a3ec43b3450d845b5ba2043e311e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cc4c476b9b9445da8011c751ea83adf",
            "placeholder": "​",
            "style": "IPY_MODEL_7873993f209b4ada8f23ed79927824ff",
            "value": " 3760/3760 [00:00&lt;00:00, 128170.27 examples/s]"
          }
        },
        "8b39389aded949ad8eb393aa4543cf23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88b9fc2a34aa426d95b095c0939ebc42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8686ac8daa3b44b8ad562f37f32289df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0726f1576eb44d7b4f623d82e239856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89cc6d30d6e0416e8997b57042499df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cc4c476b9b9445da8011c751ea83adf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7873993f209b4ada8f23ed79927824ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}